{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Dataset\n",
    "\n",
    "## What happens when you smash things together near the speed of light?\n",
    "\n",
    "The Higgs boson has been sought after for decades. Can we use machine learning to gather any more information about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "callback = keras.callbacks.TensorBoard(log_dir='./logs',histogram_freq=0, batch_size=32, write_graph=True)\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['Class Label', 'lepton pT', 'lepton eta', \n",
    "                'lepton phi', 'missing energy magnitude',\n",
    "                'missing energy phi', 'jet 1 pt', 'jet 1 eta',\n",
    "                'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt',  'jet 2 eta', \n",
    "                'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', \n",
    "                'jet 3 phi',' jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', \n",
    "                'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', \n",
    "                'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/HIGGS.csv', names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
       "0          1.0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1          1.0   0.907542    0.329147    0.359412                  1.497970   \n",
       "2          1.0   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3          0.0   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4          1.0   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag    ...     \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064     0.000000    ...      \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230     2.173076    ...      \n",
       "2            0.425629  1.104875   1.282322   1.381664     0.000000    ...      \n",
       "3            0.882454  1.786066  -1.646778  -0.942383     0.000000    ...      \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871     0.000000    ...      \n",
       "\n",
       "   jet 4 eta  jet 4 phi  jet 4 b-tag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767     3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819     0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461     0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356     0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041     0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.299203e-01</td>\n",
       "      <td>9.914658e-01</td>\n",
       "      <td>-8.297618e-06</td>\n",
       "      <td>-1.327225e-05</td>\n",
       "      <td>9.985364e-01</td>\n",
       "      <td>2.613459e-05</td>\n",
       "      <td>9.909152e-01</td>\n",
       "      <td>-2.027520e-05</td>\n",
       "      <td>7.716199e-06</td>\n",
       "      <td>9.999687e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.756954e-06</td>\n",
       "      <td>1.744903e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034290e+00</td>\n",
       "      <td>1.024805e+00</td>\n",
       "      <td>1.050554e+00</td>\n",
       "      <td>1.009742e+00</td>\n",
       "      <td>9.729596e-01</td>\n",
       "      <td>1.033036e+00</td>\n",
       "      <td>9.598120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.991040e-01</td>\n",
       "      <td>5.653777e-01</td>\n",
       "      <td>1.008827e+00</td>\n",
       "      <td>1.006346e+00</td>\n",
       "      <td>6.000185e-01</td>\n",
       "      <td>1.006326e+00</td>\n",
       "      <td>4.749747e-01</td>\n",
       "      <td>1.009303e+00</td>\n",
       "      <td>1.005901e+00</td>\n",
       "      <td>1.027808e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007694e+00</td>\n",
       "      <td>1.006366e+00</td>\n",
       "      <td>1.400209e+00</td>\n",
       "      <td>6.746354e-01</td>\n",
       "      <td>3.808074e-01</td>\n",
       "      <td>1.645763e-01</td>\n",
       "      <td>3.974453e-01</td>\n",
       "      <td>5.254063e-01</td>\n",
       "      <td>3.652556e-01</td>\n",
       "      <td>3.133378e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.746966e-01</td>\n",
       "      <td>-2.434976e+00</td>\n",
       "      <td>-1.742508e+00</td>\n",
       "      <td>2.370088e-04</td>\n",
       "      <td>-1.743944e+00</td>\n",
       "      <td>1.375024e-01</td>\n",
       "      <td>-2.969725e+00</td>\n",
       "      <td>-1.741237e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.497265e+00</td>\n",
       "      <td>-1.742691e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507046e-02</td>\n",
       "      <td>1.986757e-01</td>\n",
       "      <td>8.304866e-02</td>\n",
       "      <td>1.320062e-01</td>\n",
       "      <td>4.786215e-02</td>\n",
       "      <td>2.951122e-01</td>\n",
       "      <td>3.307214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.907533e-01</td>\n",
       "      <td>-7.383225e-01</td>\n",
       "      <td>-8.719308e-01</td>\n",
       "      <td>5.768156e-01</td>\n",
       "      <td>-8.712081e-01</td>\n",
       "      <td>6.789927e-01</td>\n",
       "      <td>-6.872450e-01</td>\n",
       "      <td>-8.680962e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.141902e-01</td>\n",
       "      <td>-8.714789e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.906095e-01</td>\n",
       "      <td>8.462266e-01</td>\n",
       "      <td>9.857525e-01</td>\n",
       "      <td>7.675732e-01</td>\n",
       "      <td>6.738168e-01</td>\n",
       "      <td>8.193964e-01</td>\n",
       "      <td>7.703901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.533714e-01</td>\n",
       "      <td>-5.415563e-05</td>\n",
       "      <td>-2.410638e-04</td>\n",
       "      <td>8.916277e-01</td>\n",
       "      <td>2.125454e-04</td>\n",
       "      <td>8.948193e-01</td>\n",
       "      <td>-2.543566e-05</td>\n",
       "      <td>5.813991e-05</td>\n",
       "      <td>1.086538e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.721330e-04</td>\n",
       "      <td>-2.642369e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.949304e-01</td>\n",
       "      <td>9.506853e-01</td>\n",
       "      <td>9.897798e-01</td>\n",
       "      <td>9.165110e-01</td>\n",
       "      <td>8.733798e-01</td>\n",
       "      <td>9.473447e-01</td>\n",
       "      <td>8.719701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236226e+00</td>\n",
       "      <td>7.382142e-01</td>\n",
       "      <td>8.709940e-01</td>\n",
       "      <td>1.293056e+00</td>\n",
       "      <td>8.714708e-01</td>\n",
       "      <td>1.170740e+00</td>\n",
       "      <td>6.871941e-01</td>\n",
       "      <td>8.683126e-01</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.141017e-01</td>\n",
       "      <td>8.716055e-01</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>1.024730e+00</td>\n",
       "      <td>1.083493e+00</td>\n",
       "      <td>1.020528e+00</td>\n",
       "      <td>1.142226e+00</td>\n",
       "      <td>1.138439e+00</td>\n",
       "      <td>1.140458e+00</td>\n",
       "      <td>1.059248e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.209891e+01</td>\n",
       "      <td>2.434868e+00</td>\n",
       "      <td>1.743236e+00</td>\n",
       "      <td>1.539682e+01</td>\n",
       "      <td>1.743257e+00</td>\n",
       "      <td>9.940391e+00</td>\n",
       "      <td>2.969674e+00</td>\n",
       "      <td>1.741454e+00</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498009e+00</td>\n",
       "      <td>1.743372e+00</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>4.019237e+01</td>\n",
       "      <td>2.037278e+01</td>\n",
       "      <td>7.992739e+00</td>\n",
       "      <td>1.426244e+01</td>\n",
       "      <td>1.776285e+01</td>\n",
       "      <td>1.149652e+01</td>\n",
       "      <td>8.374498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Label     lepton pT    lepton eta    lepton phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   5.299203e-01  9.914658e-01 -8.297618e-06 -1.327225e-05   \n",
       "std    4.991040e-01  5.653777e-01  1.008827e+00  1.006346e+00   \n",
       "min    0.000000e+00  2.746966e-01 -2.434976e+00 -1.742508e+00   \n",
       "25%    0.000000e+00  5.907533e-01 -7.383225e-01 -8.719308e-01   \n",
       "50%    1.000000e+00  8.533714e-01 -5.415563e-05 -2.410638e-04   \n",
       "75%    1.000000e+00  1.236226e+00  7.382142e-01  8.709940e-01   \n",
       "max    1.000000e+00  1.209891e+01  2.434868e+00  1.743236e+00   \n",
       "\n",
       "       missing energy magnitude  missing energy phi      jet 1 pt  \\\n",
       "count              1.100000e+07        1.100000e+07  1.100000e+07   \n",
       "mean               9.985364e-01        2.613459e-05  9.909152e-01   \n",
       "std                6.000185e-01        1.006326e+00  4.749747e-01   \n",
       "min                2.370088e-04       -1.743944e+00  1.375024e-01   \n",
       "25%                5.768156e-01       -8.712081e-01  6.789927e-01   \n",
       "50%                8.916277e-01        2.125454e-04  8.948193e-01   \n",
       "75%                1.293056e+00        8.714708e-01  1.170740e+00   \n",
       "max                1.539682e+01        1.743257e+00  9.940391e+00   \n",
       "\n",
       "          jet 1 eta     jet 1 phi   jet 1 b-tag      ...          jet 4 eta  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07      ...       1.100000e+07   \n",
       "mean  -2.027520e-05  7.716199e-06  9.999687e-01      ...      -5.756954e-06   \n",
       "std    1.009303e+00  1.005901e+00  1.027808e+00      ...       1.007694e+00   \n",
       "min   -2.969725e+00 -1.741237e+00  0.000000e+00      ...      -2.497265e+00   \n",
       "25%   -6.872450e-01 -8.680962e-01  0.000000e+00      ...      -7.141902e-01   \n",
       "50%   -2.543566e-05  5.813991e-05  1.086538e+00      ...       3.721330e-04   \n",
       "75%    6.871941e-01  8.683126e-01  2.173076e+00      ...       7.141017e-01   \n",
       "max    2.969674e+00  1.741454e+00  2.173076e+00      ...       2.498009e+00   \n",
       "\n",
       "          jet 4 phi   jet 4 b-tag          m_jj         m_jjj          m_lv  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.744903e-05  1.000000e+00  1.034290e+00  1.024805e+00  1.050554e+00   \n",
       "std    1.006366e+00  1.400209e+00  6.746354e-01  3.808074e-01  1.645763e-01   \n",
       "min   -1.742691e+00  0.000000e+00  7.507046e-02  1.986757e-01  8.304866e-02   \n",
       "25%   -8.714789e-01  0.000000e+00  7.906095e-01  8.462266e-01  9.857525e-01   \n",
       "50%   -2.642369e-04  0.000000e+00  8.949304e-01  9.506853e-01  9.897798e-01   \n",
       "75%    8.716055e-01  3.101961e+00  1.024730e+00  1.083493e+00  1.020528e+00   \n",
       "max    1.743372e+00  3.101961e+00  4.019237e+01  2.037278e+01  7.992739e+00   \n",
       "\n",
       "              m_jlv          m_bb         m_wbb        m_wwbb  \n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  \n",
       "mean   1.009742e+00  9.729596e-01  1.033036e+00  9.598120e-01  \n",
       "std    3.974453e-01  5.254063e-01  3.652556e-01  3.133378e-01  \n",
       "min    1.320062e-01  4.786215e-02  2.951122e-01  3.307214e-01  \n",
       "25%    7.675732e-01  6.738168e-01  8.193964e-01  7.703901e-01  \n",
       "50%    9.165110e-01  8.733798e-01  9.473447e-01  8.719701e-01  \n",
       "75%    1.142226e+00  1.138439e+00  1.140458e+00  1.059248e+00  \n",
       "max    1.426244e+01  1.776285e+01  1.149652e+01  8.374498e+00  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>jet 2 pt</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.374992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.812581</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.423265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
       "0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1   0.907542    0.329147    0.359412                  1.497970   \n",
       "2   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  jet 2 pt  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064     0.000000  1.374992   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230     2.173076  0.812581   \n",
       "2            0.425629  1.104875   1.282322   1.381664     0.000000  0.851737   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383     0.000000  2.423265   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871     0.000000  0.800872   \n",
       "\n",
       "     ...     jet 4 eta  jet 4 phi  jet 4 b-tag      m_jj     m_jjj      m_lv  \\\n",
       "0    ...     -0.010455  -0.045767     3.101961  1.353760  0.979563  0.978076   \n",
       "1    ...     -1.138930  -0.000819     0.000000  0.302220  0.833048  0.985700   \n",
       "2    ...      1.128848   0.900461     0.000000  0.909753  1.108330  0.985692   \n",
       "3    ...     -0.678379  -1.360356     0.000000  0.946652  1.028704  0.998656   \n",
       "4    ...     -0.373566   0.113041     0.000000  0.755856  1.361057  0.986610   \n",
       "\n",
       "      m_jlv      m_bb     m_wbb    m_wwbb  \n",
       "0  0.920005  0.721657  0.988751  0.876678  \n",
       "1  0.978098  0.779732  0.992356  0.798343  \n",
       "2  0.951331  0.803252  0.865924  0.780118  \n",
       "3  0.728281  0.869200  1.026736  0.957904  \n",
       "4  0.838085  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"Class Label\"]\n",
    "labels.head()\n",
    "\n",
    "df.drop([\"Class Label\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try using decision tree\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_X_vals = scaler.transform(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X_vals, labels, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6783970129475747\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "fitted = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn import tree\n",
    "# import graphviz\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                          feature_names=df.keys(),  \n",
    "#                          class_names=[\"No Higgs\",\"Higgs\"],  \n",
    "#                          filled=True, rounded=True,  \n",
    "#                          special_characters=True)\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph\n",
    "#Takes too long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500000, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result = []\n",
    "accuracy_result = []\n",
    "label_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                464       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,349\n",
      "Trainable params: 1,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seq_model = Sequential()\n",
    "seq_model.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "seq_model.add(Dense(16, activation='sigmoid'))\n",
    "seq_model.add(Dense(4, activation='sigmoid'))\n",
    "seq_model.add(Dense(1, activation='sigmoid'))\n",
    "seq_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/10\n",
      "5500000/5500000 [==============================] - 153s 28us/step - loss: 0.6722 - acc: 0.5746 - val_loss: 0.6370 - val_acc: 0.6347\n",
      "Epoch 2/10\n",
      "5500000/5500000 [==============================] - 163s 30us/step - loss: 0.6268 - acc: 0.6503 - val_loss: 0.6142 - val_acc: 0.6667\n",
      "Epoch 3/10\n",
      "5500000/5500000 [==============================] - 180s 33us/step - loss: 0.5996 - acc: 0.6793 - val_loss: 0.5843 - val_acc: 0.6926\n",
      "Epoch 4/10\n",
      "5500000/5500000 [==============================] - 190s 35us/step - loss: 0.5736 - acc: 0.6998 - val_loss: 0.5631 - val_acc: 0.7065\n",
      "Epoch 5/10\n",
      "5500000/5500000 [==============================] - 174s 32us/step - loss: 0.5569 - acc: 0.7113 - val_loss: 0.5506 - val_acc: 0.7160\n",
      "Epoch 6/10\n",
      "5500000/5500000 [==============================] - 171s 31us/step - loss: 0.5478 - acc: 0.7176 - val_loss: 0.5439 - val_acc: 0.7204\n",
      "Epoch 7/10\n",
      "5500000/5500000 [==============================] - 175s 32us/step - loss: 0.5418 - acc: 0.7220 - val_loss: 0.5384 - val_acc: 0.7246\n",
      "Epoch 8/10\n",
      "5500000/5500000 [==============================] - 157s 28us/step - loss: 0.5370 - acc: 0.7254 - val_loss: 0.5352 - val_acc: 0.7264\n",
      "Epoch 9/10\n",
      "5500000/5500000 [==============================] - 156s 28us/step - loss: 0.5341 - acc: 0.7273 - val_loss: 0.5318 - val_acc: 0.7287\n",
      "Epoch 10/10\n",
      "5500000/5500000 [==============================] - 146s 27us/step - loss: 0.5321 - acc: 0.7285 - val_loss: 0.5305 - val_acc: 0.7295\n"
     ]
    }
   ],
   "source": [
    "ret_val = seq_model.fit(X_train, y_train, \n",
    "              batch_size=64, epochs=10, \n",
    "              verbose=1, validation_data=(X_test, y_test),\n",
    "              callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".53\")\n",
    "accuracy_result.append(\".72\")\n",
    "label_result.append(\"4LySigBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                464       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,349\n",
      "Trainable params: 1,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tanh_model = Sequential()\n",
    "tanh_model.add(Dense(28, activation='tanh', input_shape=(28,)))\n",
    "tanh_model.add(Dense(16, activation='tanh'))\n",
    "tanh_model.add(Dense(4, activation='tanh'))\n",
    "tanh_model.add(Dense(1, activation='sigmoid'))\n",
    "tanh_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "tanh_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8ce7697ed29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtanh_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mallback = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=False, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/10\n",
      "5500000/5500000 [==============================] - 198s 36us/step - loss: 0.5785 - acc: 0.6925 - val_loss: 0.5508 - val_acc: 0.7154\n",
      "Epoch 2/10\n",
      "5500000/5500000 [==============================] - 144s 26us/step - loss: 0.5400 - acc: 0.7228 - val_loss: 0.5334 - val_acc: 0.7273\n",
      "Epoch 3/10\n",
      "5500000/5500000 [==============================] - 142s 26us/step - loss: 0.5301 - acc: 0.7302 - val_loss: 0.5267 - val_acc: 0.7326\n",
      "Epoch 4/10\n",
      "5500000/5500000 [==============================] - 142s 26us/step - loss: 0.5252 - acc: 0.7335 - val_loss: 0.5231 - val_acc: 0.7347\n",
      "Epoch 5/10\n",
      "5500000/5500000 [==============================] - 143s 26us/step - loss: 0.5220 - acc: 0.7357 - val_loss: 0.5202 - val_acc: 0.7368\n",
      "Epoch 6/10\n",
      "5500000/5500000 [==============================] - 141s 26us/step - loss: 0.5200 - acc: 0.7371 - val_loss: 0.5190 - val_acc: 0.7379\n",
      "Epoch 7/10\n",
      "5500000/5500000 [==============================] - 142s 26us/step - loss: 0.5186 - acc: 0.7379 - val_loss: 0.5172 - val_acc: 0.7386\n",
      "Epoch 8/10\n",
      "5500000/5500000 [==============================] - 191s 35us/step - loss: 0.5173 - acc: 0.7386 - val_loss: 0.5160 - val_acc: 0.7392\n",
      "Epoch 9/10\n",
      "5500000/5500000 [==============================] - 202s 37us/step - loss: 0.5163 - acc: 0.7391 - val_loss: 0.5163 - val_acc: 0.7393\n",
      "Epoch 10/10\n",
      "5500000/5500000 [==============================] - 208s 38us/step - loss: 0.5156 - acc: 0.7396 - val_loss: 0.5143 - val_acc: 0.7403\n"
     ]
    }
   ],
   "source": [
    "ret_result = tanh_model.fit(X_train, y_train, \n",
    "               batch_size=64, epochs=10, \n",
    "               verbose=1, validation_data=(X_test, y_test),\n",
    "               callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.69253763636363641,\n",
       "  0.72279745454545452,\n",
       "  0.73016545454545456,\n",
       "  0.73351327272727274,\n",
       "  0.73571236363636361,\n",
       "  0.73706690909090911,\n",
       "  0.73790909090909096,\n",
       "  0.73862836363636364,\n",
       "  0.73912145454545453,\n",
       "  0.73957854545454549],\n",
       " 'loss': [0.57854886867783284,\n",
       "  0.54002717553502866,\n",
       "  0.53006005364192621,\n",
       "  0.52516268034293434,\n",
       "  0.52201792437882855,\n",
       "  0.52000118659834427,\n",
       "  0.51856294563293459,\n",
       "  0.51733960099549725,\n",
       "  0.51631520341283621,\n",
       "  0.51555496920290855],\n",
       " 'val_acc': [0.71537672727272728,\n",
       "  0.72732618181818187,\n",
       "  0.73259181818181818,\n",
       "  0.73465454545454545,\n",
       "  0.73677963636363641,\n",
       "  0.73785199999999995,\n",
       "  0.73855490909090904,\n",
       "  0.73923690909090911,\n",
       "  0.73925418181818181,\n",
       "  0.74026418181818177],\n",
       " 'val_loss': [0.55080517289074982,\n",
       "  0.53336716985598476,\n",
       "  0.52667349213894932,\n",
       "  0.52312577815506678,\n",
       "  0.52024833676043425,\n",
       "  0.51895407090273771,\n",
       "  0.51724811456801678,\n",
       "  0.51596045256129175,\n",
       "  0.51628270099778606,\n",
       "  0.51431050921838939]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ret_result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".59\")\n",
    "accuracy_result.append(\".53\")\n",
    "label_result.append(\"3LyTanhBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_lay = Sequential()\n",
    "two_lay.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "two_lay.add(Dense(10, activation='sigmoid'))\n",
    "two_lay.add(Dense(1, activation='sigmoid'))\n",
    "two_lay.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "two_lay.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/5\n",
      "5500000/5500000 [==============================] - 139s 25us/step - loss: 0.6472 - acc: 0.6181 - val_loss: 0.6269 - val_acc: 0.6490\n",
      "Epoch 2/5\n",
      "5500000/5500000 [==============================] - 138s 25us/step - loss: 0.6111 - acc: 0.6653 - val_loss: 0.5930 - val_acc: 0.6837\n",
      "Epoch 3/5\n",
      "5500000/5500000 [==============================] - 144s 26us/step - loss: 0.5813 - acc: 0.6934 - val_loss: 0.5720 - val_acc: 0.7005\n",
      "Epoch 4/5\n",
      "5500000/5500000 [==============================] - 138s 25us/step - loss: 0.5668 - acc: 0.7044 - val_loss: 0.5617 - val_acc: 0.7077\n",
      "Epoch 5/5\n",
      "5500000/5500000 [==============================] - 137s 25us/step - loss: 0.5583 - acc: 0.7111 - val_loss: 0.5546 - val_acc: 0.7144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c86588198>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=5, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".55\")\n",
    "accuracy_result.append(\".71\")\n",
    "label_result.append(\"3LySigBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_lay = Sequential()\n",
    "two_lay.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "two_lay.add(Dense(10, activation='sigmoid'))\n",
    "two_lay.add(Dense(1, activation='sigmoid'))\n",
    "two_lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "two_lay.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 151s 28us/step - loss: 0.5544 - acc: 0.7112 - val_loss: 0.5338 - val_acc: 0.7271\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 177s 32us/step - loss: 0.5282 - acc: 0.7311 - val_loss: 0.5237 - val_acc: 0.7341\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 179s 33us/step - loss: 0.5230 - acc: 0.7342 - val_loss: 0.5209 - val_acc: 0.7355\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 170s 31us/step - loss: 0.5206 - acc: 0.7358 - val_loss: 0.5193 - val_acc: 0.7367\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 206s 37us/step - loss: 0.5190 - acc: 0.7369 - val_loss: 0.5192 - val_acc: 0.7368\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 191s 35us/step - loss: 0.5180 - acc: 0.7376 - val_loss: 0.5170 - val_acc: 0.7379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c215a2710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".52\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigBinCrosAdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rms_prop = Sequential()\n",
    "rms_prop.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "rms_prop.add(Dense(10, activation='sigmoid'))\n",
    "rms_prop.add(Dense(1, activation='sigmoid'))\n",
    "rms_prop.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "rms_prop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 167s 30us/step - loss: 0.5594 - acc: 0.7074 - val_loss: 0.5351 - val_acc: 0.7264\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 153s 28us/step - loss: 0.5299 - acc: 0.7299 - val_loss: 0.5253 - val_acc: 0.7331\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 154s 28us/step - loss: 0.5239 - acc: 0.7341 - val_loss: 0.5236 - val_acc: 0.7344\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 156s 28us/step - loss: 0.5216 - acc: 0.7358 - val_loss: 0.5246 - val_acc: 0.7331\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 144s 26us/step - loss: 0.5202 - acc: 0.7366 - val_loss: 0.5195 - val_acc: 0.7370\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 153s 28us/step - loss: 0.5192 - acc: 0.7374 - val_loss: 0.5190 - val_acc: 0.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2071ecc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_prop.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".51\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigBinCrosRMSP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kld = Sequential()\n",
    "kld.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "kld.add(Dense(10, activation='sigmoid'))\n",
    "kld.add(Dense(1, activation='sigmoid'))\n",
    "kld.compile(loss='kullback_leibler_divergence', optimizer='rmsprop', metrics=['accuracy'])\n",
    "kld.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 153s 28us/step - loss: 0.5172 - acc: 0.7380 - val_loss: 0.5173 - val_acc: 0.7375\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 166s 30us/step - loss: 0.5166 - acc: 0.7384 - val_loss: 0.5165 - val_acc: 0.7382\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 176s 32us/step - loss: 0.5162 - acc: 0.7385 - val_loss: 0.5172 - val_acc: 0.7378\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: 0.5158 - acc: 0.7388 - val_loss: 0.5149 - val_acc: 0.7395\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 164s 30us/step - loss: 0.5156 - acc: 0.7387 - val_loss: 0.5151 - val_acc: 0.7391\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: 0.5154 - acc: 0.7391 - val_loss: 0.5143 - val_acc: 0.7399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e3d1278>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".51\")\n",
    "accuracy_result.append(\".74\")\n",
    "label_result.append(\"3LySigBinCrosAdam2nd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "poisson = Sequential()\n",
    "poisson.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "poisson.add(Dense(10, activation='sigmoid'))\n",
    "poisson.add(Dense(1, activation='sigmoid'))\n",
    "poisson.compile(loss='poisson', optimizer='rmsprop', metrics=['accuracy'])\n",
    "poisson.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 195s 35us/step - loss: 0.5152 - acc: 0.7391 - val_loss: 0.5146 - val_acc: 0.7395\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 188s 34us/step - loss: 0.5151 - acc: 0.7393 - val_loss: 0.5148 - val_acc: 0.7391\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 187s 34us/step - loss: 0.5149 - acc: 0.7394 - val_loss: 0.5145 - val_acc: 0.7396\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 175s 32us/step - loss: 0.5146 - acc: 0.7396 - val_loss: 0.5139 - val_acc: 0.7400\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 207s 38us/step - loss: 0.5145 - acc: 0.7397 - val_loss: 0.5141 - val_acc: 0.7400\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 167s 30us/step - loss: 0.5142 - acc: 0.7399 - val_loss: 0.5138 - val_acc: 0.7399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c21807c50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test), callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Duplicate run of previously run model :(\n",
    "# loss_result.append(\".51\")\n",
    "# accuracy_result.append(\".73\")\n",
    "# label_result.append(\"3LySigBinCrosAdam2nd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 166s 30us/step - loss: 7.5472e-04 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 158s 29us/step - loss: -7.5802e-07 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 150s 27us/step - loss: -7.5802e-07 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: -7.5802e-07 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 162s 29us/step - loss: -7.5802e-07 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 158s 29us/step - loss: -7.5802e-07 - acc: 0.5297 - val_loss: -7.5734e-07 - val_acc: 0.5301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c20beab00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kld.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".0000007\")\n",
    "accuracy_result.append(\".53\")\n",
    "label_result.append(\"3LyKLDRmsProp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 165s 30us/step - loss: 0.8033 - acc: 0.7060 - val_loss: 0.7916 - val_acc: 0.7259\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 148s 27us/step - loss: 0.7892 - acc: 0.7292 - val_loss: 0.7872 - val_acc: 0.7325\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 148s 27us/step - loss: 0.7864 - acc: 0.7330 - val_loss: 0.7860 - val_acc: 0.7337\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 158s 29us/step - loss: 0.7854 - acc: 0.7345 - val_loss: 0.7850 - val_acc: 0.7354\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 212s 38us/step - loss: 0.7848 - acc: 0.7353 - val_loss: 0.7850 - val_acc: 0.7353\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 190s 35us/step - loss: 0.7845 - acc: 0.7354 - val_loss: 0.7843 - val_acc: 0.7363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2255b128>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test),callbacks=[mallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".78\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigPoisRMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(activation_fn, loss_fn, optimizer_fn):\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(28, activation=activation_fn, input_shape=(28,)))\n",
    "    seq.add(Dense(10, activation=activation_fn))\n",
    "    seq.add(Dense(1, activation=activation_fn))\n",
    "    seq.compile(loss=loss_fn, optimizer=optimizer_fn, metrics=['accuracy'])\n",
    "    seq.summary()\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAIMCAYAAAB7di0zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c259e5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# display(loss_result.pop(7))\n",
    "# display(loss_result)\n",
    "accycolor = []\n",
    "#Generate Colors on red/green axis based on execution time\n",
    "for index in range(0,len(loss_result)):\n",
    "    \n",
    "    percent_red = float(loss_result[index])\n",
    "    percent_green = 1 - percent_red\n",
    "    red_10 = int(percent_red * 255)\n",
    "    green_10 = int(percent_green * 255)\n",
    "    red_16 = str(hex(red_10))[-2:].replace(\"x\", \"0\")\n",
    "    green_16 = str(hex(green_10))[-2:].replace(\"x\", \"0\")\n",
    "    accycolor.append(\"#\"+str(red_16)+str(green_16)+\"88\")\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(11, 9))\n",
    "rects = ax.bar(label_result, accuracy_result, color=accycolor)\n",
    "random_chance = 0\n",
    "# plot.axhline(y=random_chance, color='r', linestyle='-')\n",
    "ax.set_ylim(ymin=0)\n",
    "# Indicate Times.\n",
    "labels = [\"%s\" % l for l in label_result]\n",
    "\n",
    "\n",
    "plot.plot()\n",
    "for rect, label in zip(rects, labels):\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, .1, label,ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS AN A AMZING DATASET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvYAAAIMCAYAAACe6OhfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgR7AACYAMEeAAAmQLAHAIAJ+B/KUrrCBLpfkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c258d3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losscolor = []\n",
    "#Generate Colors on red/green axis based on execution time\n",
    "for index in range(0,len(loss_result)):\n",
    "    \n",
    "    percent_red = float(loss_result[index])\n",
    "    percent_green = 1 - percent_red\n",
    "    red_10 = int(percent_red * 255)\n",
    "    green_10 = int(percent_green * 255)\n",
    "    red_16 = str(hex(red_10))[-2:].replace(\"x\", \"0\")\n",
    "    green_16 = str(hex(green_10))[-2:].replace(\"x\", \"0\")\n",
    "    losscolor.append(\"#\"+str(red_16)+str(green_16)+\"88\")\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(11, 9))\n",
    "\n",
    "print('THIS IS AN A AMZING DATASET')\n",
    "# print(type(left))\n",
    "rects = ax.barh(label_result, accuracy_result, color=accycolor)\n",
    "random_chance = 0\n",
    "plot.axhline(y=random_chance, color='r', linestyle='-')\n",
    "\n",
    "# Indicate Times.\n",
    "labels = [\"%s\" % l for l in label_result]\n",
    "\n",
    "\n",
    "plot.plot()\n",
    "# for rect, label in zip(rects, labels):\n",
    "#     ax.text(rect.get_x() + rect.get_width() / 2, .1, label,ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
