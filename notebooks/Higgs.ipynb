{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Dataset\n",
    "\n",
    "## What happens when you smash things together near the speed of light?\n",
    "\n",
    "The Higgs boson has been sought after for decades. Can we use machine learning to gather any more information about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['Class Label', 'lepton pT', 'lepton eta', \n",
    "                'lepton phi', 'missing energy magnitude',\n",
    "                'missing energy phi', 'jet 1 pt', 'jet 1 eta',\n",
    "                'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt',  'jet 2 eta', \n",
    "                'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', \n",
    "                'jet 3 phi',' jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', \n",
    "                'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', \n",
    "                'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/HIGGS.csv', names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Label  lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
       "0          1.0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1          1.0   0.907542    0.329147    0.359412                  1.497970   \n",
       "2          1.0   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3          0.0   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4          1.0   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag    ...     \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064     0.000000    ...      \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230     2.173076    ...      \n",
       "2            0.425629  1.104875   1.282322   1.381664     0.000000    ...      \n",
       "3            0.882454  1.786066  -1.646778  -0.942383     0.000000    ...      \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871     0.000000    ...      \n",
       "\n",
       "   jet 4 eta  jet 4 phi  jet 4 b-tag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767     3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819     0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461     0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356     0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041     0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.299203e-01</td>\n",
       "      <td>9.914658e-01</td>\n",
       "      <td>-8.297618e-06</td>\n",
       "      <td>-1.327225e-05</td>\n",
       "      <td>9.985364e-01</td>\n",
       "      <td>2.613459e-05</td>\n",
       "      <td>9.909152e-01</td>\n",
       "      <td>-2.027520e-05</td>\n",
       "      <td>7.716199e-06</td>\n",
       "      <td>9.999687e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.756954e-06</td>\n",
       "      <td>1.744903e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034290e+00</td>\n",
       "      <td>1.024805e+00</td>\n",
       "      <td>1.050554e+00</td>\n",
       "      <td>1.009742e+00</td>\n",
       "      <td>9.729596e-01</td>\n",
       "      <td>1.033036e+00</td>\n",
       "      <td>9.598120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.991040e-01</td>\n",
       "      <td>5.653777e-01</td>\n",
       "      <td>1.008827e+00</td>\n",
       "      <td>1.006346e+00</td>\n",
       "      <td>6.000185e-01</td>\n",
       "      <td>1.006326e+00</td>\n",
       "      <td>4.749747e-01</td>\n",
       "      <td>1.009303e+00</td>\n",
       "      <td>1.005901e+00</td>\n",
       "      <td>1.027808e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007694e+00</td>\n",
       "      <td>1.006366e+00</td>\n",
       "      <td>1.400209e+00</td>\n",
       "      <td>6.746354e-01</td>\n",
       "      <td>3.808074e-01</td>\n",
       "      <td>1.645763e-01</td>\n",
       "      <td>3.974453e-01</td>\n",
       "      <td>5.254063e-01</td>\n",
       "      <td>3.652556e-01</td>\n",
       "      <td>3.133378e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.746966e-01</td>\n",
       "      <td>-2.434976e+00</td>\n",
       "      <td>-1.742508e+00</td>\n",
       "      <td>2.370088e-04</td>\n",
       "      <td>-1.743944e+00</td>\n",
       "      <td>1.375024e-01</td>\n",
       "      <td>-2.969725e+00</td>\n",
       "      <td>-1.741237e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.497265e+00</td>\n",
       "      <td>-1.742691e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507046e-02</td>\n",
       "      <td>1.986757e-01</td>\n",
       "      <td>8.304866e-02</td>\n",
       "      <td>1.320062e-01</td>\n",
       "      <td>4.786215e-02</td>\n",
       "      <td>2.951122e-01</td>\n",
       "      <td>3.307214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.907533e-01</td>\n",
       "      <td>-7.383225e-01</td>\n",
       "      <td>-8.719308e-01</td>\n",
       "      <td>5.768156e-01</td>\n",
       "      <td>-8.712081e-01</td>\n",
       "      <td>6.789927e-01</td>\n",
       "      <td>-6.872450e-01</td>\n",
       "      <td>-8.680962e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.141902e-01</td>\n",
       "      <td>-8.714789e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.906095e-01</td>\n",
       "      <td>8.462266e-01</td>\n",
       "      <td>9.857525e-01</td>\n",
       "      <td>7.675732e-01</td>\n",
       "      <td>6.738168e-01</td>\n",
       "      <td>8.193964e-01</td>\n",
       "      <td>7.703901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.533714e-01</td>\n",
       "      <td>-5.415563e-05</td>\n",
       "      <td>-2.410638e-04</td>\n",
       "      <td>8.916277e-01</td>\n",
       "      <td>2.125454e-04</td>\n",
       "      <td>8.948193e-01</td>\n",
       "      <td>-2.543566e-05</td>\n",
       "      <td>5.813991e-05</td>\n",
       "      <td>1.086538e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.721330e-04</td>\n",
       "      <td>-2.642369e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.949304e-01</td>\n",
       "      <td>9.506853e-01</td>\n",
       "      <td>9.897798e-01</td>\n",
       "      <td>9.165110e-01</td>\n",
       "      <td>8.733798e-01</td>\n",
       "      <td>9.473447e-01</td>\n",
       "      <td>8.719701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236226e+00</td>\n",
       "      <td>7.382142e-01</td>\n",
       "      <td>8.709940e-01</td>\n",
       "      <td>1.293056e+00</td>\n",
       "      <td>8.714708e-01</td>\n",
       "      <td>1.170740e+00</td>\n",
       "      <td>6.871941e-01</td>\n",
       "      <td>8.683126e-01</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.141017e-01</td>\n",
       "      <td>8.716055e-01</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>1.024730e+00</td>\n",
       "      <td>1.083493e+00</td>\n",
       "      <td>1.020528e+00</td>\n",
       "      <td>1.142226e+00</td>\n",
       "      <td>1.138439e+00</td>\n",
       "      <td>1.140458e+00</td>\n",
       "      <td>1.059248e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.209891e+01</td>\n",
       "      <td>2.434868e+00</td>\n",
       "      <td>1.743236e+00</td>\n",
       "      <td>1.539682e+01</td>\n",
       "      <td>1.743257e+00</td>\n",
       "      <td>9.940391e+00</td>\n",
       "      <td>2.969674e+00</td>\n",
       "      <td>1.741454e+00</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498009e+00</td>\n",
       "      <td>1.743372e+00</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>4.019237e+01</td>\n",
       "      <td>2.037278e+01</td>\n",
       "      <td>7.992739e+00</td>\n",
       "      <td>1.426244e+01</td>\n",
       "      <td>1.776285e+01</td>\n",
       "      <td>1.149652e+01</td>\n",
       "      <td>8.374498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Label     lepton pT    lepton eta    lepton phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   5.299203e-01  9.914658e-01 -8.297618e-06 -1.327225e-05   \n",
       "std    4.991040e-01  5.653777e-01  1.008827e+00  1.006346e+00   \n",
       "min    0.000000e+00  2.746966e-01 -2.434976e+00 -1.742508e+00   \n",
       "25%    0.000000e+00  5.907533e-01 -7.383225e-01 -8.719308e-01   \n",
       "50%    1.000000e+00  8.533714e-01 -5.415563e-05 -2.410638e-04   \n",
       "75%    1.000000e+00  1.236226e+00  7.382142e-01  8.709940e-01   \n",
       "max    1.000000e+00  1.209891e+01  2.434868e+00  1.743236e+00   \n",
       "\n",
       "       missing energy magnitude  missing energy phi      jet 1 pt  \\\n",
       "count              1.100000e+07        1.100000e+07  1.100000e+07   \n",
       "mean               9.985364e-01        2.613459e-05  9.909152e-01   \n",
       "std                6.000185e-01        1.006326e+00  4.749747e-01   \n",
       "min                2.370088e-04       -1.743944e+00  1.375024e-01   \n",
       "25%                5.768156e-01       -8.712081e-01  6.789927e-01   \n",
       "50%                8.916277e-01        2.125454e-04  8.948193e-01   \n",
       "75%                1.293056e+00        8.714708e-01  1.170740e+00   \n",
       "max                1.539682e+01        1.743257e+00  9.940391e+00   \n",
       "\n",
       "          jet 1 eta     jet 1 phi   jet 1 b-tag      ...          jet 4 eta  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07      ...       1.100000e+07   \n",
       "mean  -2.027520e-05  7.716199e-06  9.999687e-01      ...      -5.756954e-06   \n",
       "std    1.009303e+00  1.005901e+00  1.027808e+00      ...       1.007694e+00   \n",
       "min   -2.969725e+00 -1.741237e+00  0.000000e+00      ...      -2.497265e+00   \n",
       "25%   -6.872450e-01 -8.680962e-01  0.000000e+00      ...      -7.141902e-01   \n",
       "50%   -2.543566e-05  5.813991e-05  1.086538e+00      ...       3.721330e-04   \n",
       "75%    6.871941e-01  8.683126e-01  2.173076e+00      ...       7.141017e-01   \n",
       "max    2.969674e+00  1.741454e+00  2.173076e+00      ...       2.498009e+00   \n",
       "\n",
       "          jet 4 phi   jet 4 b-tag          m_jj         m_jjj          m_lv  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.744903e-05  1.000000e+00  1.034290e+00  1.024805e+00  1.050554e+00   \n",
       "std    1.006366e+00  1.400209e+00  6.746354e-01  3.808074e-01  1.645763e-01   \n",
       "min   -1.742691e+00  0.000000e+00  7.507046e-02  1.986757e-01  8.304866e-02   \n",
       "25%   -8.714789e-01  0.000000e+00  7.906095e-01  8.462266e-01  9.857525e-01   \n",
       "50%   -2.642369e-04  0.000000e+00  8.949304e-01  9.506853e-01  9.897798e-01   \n",
       "75%    8.716055e-01  3.101961e+00  1.024730e+00  1.083493e+00  1.020528e+00   \n",
       "max    1.743372e+00  3.101961e+00  4.019237e+01  2.037278e+01  7.992739e+00   \n",
       "\n",
       "              m_jlv          m_bb         m_wbb        m_wwbb  \n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  \n",
       "mean   1.009742e+00  9.729596e-01  1.033036e+00  9.598120e-01  \n",
       "std    3.974453e-01  5.254063e-01  3.652556e-01  3.133378e-01  \n",
       "min    1.320062e-01  4.786215e-02  2.951122e-01  3.307214e-01  \n",
       "25%    7.675732e-01  6.738168e-01  8.193964e-01  7.703901e-01  \n",
       "50%    9.165110e-01  8.733798e-01  9.473447e-01  8.719701e-01  \n",
       "75%    1.142226e+00  1.138439e+00  1.140458e+00  1.059248e+00  \n",
       "max    1.426244e+01  1.776285e+01  1.149652e+01  8.374498e+00  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>jet 2 pt</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.374992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.812581</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.423265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lepton pT  lepton eta  lepton phi  missing energy magnitude  \\\n",
       "0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1   0.907542    0.329147    0.359412                  1.497970   \n",
       "2   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  jet 2 pt  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064     0.000000  1.374992   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230     2.173076  0.812581   \n",
       "2            0.425629  1.104875   1.282322   1.381664     0.000000  0.851737   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383     0.000000  2.423265   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871     0.000000  0.800872   \n",
       "\n",
       "     ...     jet 4 eta  jet 4 phi  jet 4 b-tag      m_jj     m_jjj      m_lv  \\\n",
       "0    ...     -0.010455  -0.045767     3.101961  1.353760  0.979563  0.978076   \n",
       "1    ...     -1.138930  -0.000819     0.000000  0.302220  0.833048  0.985700   \n",
       "2    ...      1.128848   0.900461     0.000000  0.909753  1.108330  0.985692   \n",
       "3    ...     -0.678379  -1.360356     0.000000  0.946652  1.028704  0.998656   \n",
       "4    ...     -0.373566   0.113041     0.000000  0.755856  1.361057  0.986610   \n",
       "\n",
       "      m_jlv      m_bb     m_wbb    m_wwbb  \n",
       "0  0.920005  0.721657  0.988751  0.876678  \n",
       "1  0.978098  0.779732  0.992356  0.798343  \n",
       "2  0.951331  0.803252  0.865924  0.780118  \n",
       "3  0.728281  0.869200  1.026736  0.957904  \n",
       "4  0.838085  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"Class Label\"]\n",
    "labels.head()\n",
    "\n",
    "df.drop([\"Class Label\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try using decision tree\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_X_vals = scaler.transform(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X_vals, labels, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6783970129475747\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "fitted = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn import tree\n",
    "# import graphviz\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                          feature_names=df.keys(),  \n",
    "#                          class_names=[\"No Higgs\",\"Higgs\"],  \n",
    "#                          filled=True, rounded=True,  \n",
    "#                          special_characters=True)\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph\n",
    "#Takes too long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500000, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_result = []\n",
    "accuracy_result = []\n",
    "label_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                464       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,349\n",
      "Trainable params: 1,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "seq_model = Sequential()\n",
    "seq_model.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "seq_model.add(Dense(16, activation='sigmoid'))\n",
    "seq_model.add(Dense(4, activation='sigmoid'))\n",
    "seq_model.add(Dense(1, activation='sigmoid'))\n",
    "seq_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/10\n",
      "5500000/5500000 [==============================] - 194s 35us/step - loss: 0.6722 - acc: 0.5745 - val_loss: 0.6370 - val_acc: 0.6347\n",
      "Epoch 2/10\n",
      "5500000/5500000 [==============================] - 193s 35us/step - loss: 0.6268 - acc: 0.6503 - val_loss: 0.6142 - val_acc: 0.6667\n",
      "Epoch 3/10\n",
      "5500000/5500000 [==============================] - 196s 36us/step - loss: 0.5996 - acc: 0.6793 - val_loss: 0.5843 - val_acc: 0.6926\n",
      "Epoch 4/10\n",
      "5500000/5500000 [==============================] - 168s 31us/step - loss: 0.5736 - acc: 0.6998 - val_loss: 0.5632 - val_acc: 0.7065\n",
      "Epoch 5/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.5569 - acc: 0.7113 - val_loss: 0.5506 - val_acc: 0.7160\n",
      "Epoch 6/10\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: 0.5478 - acc: 0.7176 - val_loss: 0.5439 - val_acc: 0.7204\n",
      "Epoch 7/10\n",
      "5500000/5500000 [==============================] - 156s 28us/step - loss: 0.5418 - acc: 0.7219 - val_loss: 0.5384 - val_acc: 0.7246\n",
      "Epoch 8/10\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: 0.5370 - acc: 0.7254 - val_loss: 0.5352 - val_acc: 0.7264\n",
      "Epoch 9/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.5341 - acc: 0.7273 - val_loss: 0.5318 - val_acc: 0.7287\n",
      "Epoch 10/10\n",
      "5500000/5500000 [==============================] - 161s 29us/step - loss: 0.5321 - acc: 0.7285 - val_loss: 0.5305 - val_acc: 0.7295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3652efd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_result.append(\".550\")\n",
    "accuracy_result.append(\".71\")\n",
    "label_result.append(\"4LySigBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                464       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,349\n",
      "Trainable params: 1,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tanh_model = Sequential()\n",
    "tanh_model.add(Dense(28, activation='tanh', input_shape=(28,)))\n",
    "tanh_model.add(Dense(16, activation='tanh'))\n",
    "tanh_model.add(Dense(4, activation='tanh'))\n",
    "tanh_model.add(Dense(1, activation='tanh'))\n",
    "tanh_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "tanh_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/10\n",
      "5500000/5500000 [==============================] - 161s 29us/step - loss: 4.9190 - acc: 0.4064 - val_loss: 7.5280 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 5.7507 - acc: 0.3095 - val_loss: 1.0301 - val_acc: 0.5297\n",
      "Epoch 3/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.7995 - acc: 0.5256 - val_loss: 0.7228 - val_acc: 0.5299\n",
      "Epoch 4/10\n",
      "5500000/5500000 [==============================] - 157s 29us/step - loss: 2.6936 - acc: 0.5045 - val_loss: 2.3532 - val_acc: 0.4212\n",
      "Epoch 5/10\n",
      "5500000/5500000 [==============================] - 157s 28us/step - loss: 0.8717 - acc: 0.5155 - val_loss: 0.7155 - val_acc: 0.5290\n",
      "Epoch 6/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.7035 - acc: 0.5259 - val_loss: 0.7006 - val_acc: 0.5298\n",
      "Epoch 7/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.6996 - acc: 0.5263 - val_loss: 0.6973 - val_acc: 0.5299\n",
      "Epoch 8/10\n",
      "5500000/5500000 [==============================] - 161s 29us/step - loss: 0.6954 - acc: 0.5264 - val_loss: 0.6934 - val_acc: 0.5300\n",
      "Epoch 9/10\n",
      "5500000/5500000 [==============================] - 161s 29us/step - loss: 0.6936 - acc: 0.5264 - val_loss: 0.6929 - val_acc: 0.5300\n",
      "Epoch 10/10\n",
      "5500000/5500000 [==============================] - 160s 29us/step - loss: 0.6931 - acc: 0.5264 - val_loss: 0.6934 - val_acc: 0.5301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3657eda0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".71\")\n",
    "accuracy_result.append(\".52\")\n",
    "label_result.append(\"3LyTanhBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_lay = Sequential()\n",
    "two_lay.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "two_lay.add(Dense(10, activation='sigmoid'))\n",
    "two_lay.add(Dense(1, activation='sigmoid'))\n",
    "two_lay.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "two_lay.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/5\n",
      "5500000/5500000 [==============================] - 252s 46us/step - loss: 0.6436 - acc: 0.6265 - val_loss: 0.6267 - val_acc: 0.6527\n",
      "Epoch 2/5\n",
      "5500000/5500000 [==============================] - 191s 35us/step - loss: 0.6179 - acc: 0.6627 - val_loss: 0.6076 - val_acc: 0.6715\n",
      "Epoch 3/5\n",
      "5500000/5500000 [==============================] - 189s 34us/step - loss: 0.5929 - acc: 0.6850 - val_loss: 0.5788 - val_acc: 0.6978\n",
      "Epoch 4/5\n",
      "5500000/5500000 [==============================] - 190s 35us/step - loss: 0.5708 - acc: 0.7028 - val_loss: 0.5639 - val_acc: 0.7066\n",
      "Epoch 5/5\n",
      "5500000/5500000 [==============================] - 195s 35us/step - loss: 0.5592 - acc: 0.7107 - val_loss: 0.5537 - val_acc: 0.7140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a36509a58>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=5, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".55\")\n",
    "accuracy_result.append(\".71\")\n",
    "label_result.append(\"3LySigBinCrosSGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_lay = Sequential()\n",
    "two_lay.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "two_lay.add(Dense(10, activation='sigmoid'))\n",
    "two_lay.add(Dense(1, activation='sigmoid'))\n",
    "two_lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "two_lay.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 218s 40us/step - loss: 0.5544 - acc: 0.7112 - val_loss: 0.5338 - val_acc: 0.7271\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 203s 37us/step - loss: 0.5282 - acc: 0.7311 - val_loss: 0.5236 - val_acc: 0.7340\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 224s 41us/step - loss: 0.5229 - acc: 0.7343 - val_loss: 0.5208 - val_acc: 0.7356\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 211s 38us/step - loss: 0.5206 - acc: 0.7359 - val_loss: 0.5192 - val_acc: 0.7368\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 205s 37us/step - loss: 0.5190 - acc: 0.7370 - val_loss: 0.5193 - val_acc: 0.7367\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 205s 37us/step - loss: 0.5180 - acc: 0.7376 - val_loss: 0.5169 - val_acc: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1fd81f28>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".52\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigBinCrosAdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rms_prop = Sequential()\n",
    "rms_prop.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "rms_prop.add(Dense(10, activation='sigmoid'))\n",
    "rms_prop.add(Dense(1, activation='sigmoid'))\n",
    "rms_prop.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "rms_prop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 212s 39us/step - loss: 0.5172 - acc: 0.7380 - val_loss: 0.5163 - val_acc: 0.7386\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 207s 38us/step - loss: 0.5166 - acc: 0.7384 - val_loss: 0.5162 - val_acc: 0.7386\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 208s 38us/step - loss: 0.5162 - acc: 0.7386 - val_loss: 0.5161 - val_acc: 0.7388\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 209s 38us/step - loss: 0.5159 - acc: 0.7388 - val_loss: 0.5150 - val_acc: 0.7395\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 211s 38us/step - loss: 0.5155 - acc: 0.7390 - val_loss: 0.5147 - val_acc: 0.7395\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 214s 39us/step - loss: 0.5153 - acc: 0.7391 - val_loss: 0.5149 - val_acc: 0.7393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f3d1518>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_prop.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".51\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigBinCrosRMSP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kld = Sequential()\n",
    "kld.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "kld.add(Dense(10, activation='sigmoid'))\n",
    "kld.add(Dense(1, activation='sigmoid'))\n",
    "kld.compile(loss='kullback_leibler_divergence', optimizer='rmsprop', metrics=['accuracy'])\n",
    "kld.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 225s 41us/step - loss: 0.5150 - acc: 0.7392 - val_loss: 0.5153 - val_acc: 0.7388\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 204s 37us/step - loss: 0.5148 - acc: 0.7393 - val_loss: 0.5150 - val_acc: 0.7390\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 210s 38us/step - loss: 0.5146 - acc: 0.7395 - val_loss: 0.5161 - val_acc: 0.7385\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 206s 38us/step - loss: 0.5144 - acc: 0.7397 - val_loss: 0.5133 - val_acc: 0.7403\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 211s 38us/step - loss: 0.5141 - acc: 0.7397 - val_loss: 0.5135 - val_acc: 0.7400\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 216s 39us/step - loss: 0.5138 - acc: 0.7400 - val_loss: 0.5127 - val_acc: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a364e1fd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".51\")\n",
    "accuracy_result.append(\".74\")\n",
    "label_result.append(\"3LyKLDAdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                290       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,113\n",
      "Trainable params: 1,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "poisson = Sequential()\n",
    "poisson.add(Dense(28, activation='sigmoid', input_shape=(28,)))\n",
    "poisson.add(Dense(10, activation='sigmoid'))\n",
    "poisson.add(Dense(1, activation='sigmoid'))\n",
    "poisson.compile(loss='poisson', optimizer='rmsprop', metrics=['accuracy'])\n",
    "poisson.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 208s 38us/step - loss: 0.5135 - acc: 0.7402 - val_loss: 0.5127 - val_acc: 0.7407\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 206s 37us/step - loss: 0.5134 - acc: 0.7403 - val_loss: 0.5132 - val_acc: 0.7402\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 196s 36us/step - loss: 0.5132 - acc: 0.7404 - val_loss: 0.5125 - val_acc: 0.7406\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 221s 40us/step - loss: 0.5131 - acc: 0.7405 - val_loss: 0.5125 - val_acc: 0.7406\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 220s 40us/step - loss: 0.5130 - acc: 0.7404 - val_loss: 0.5130 - val_acc: 0.7403\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 219s 40us/step - loss: 0.5129 - acc: 0.7405 - val_loss: 0.5133 - val_acc: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10a449be0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_lay.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 176s 32us/step - loss: 0.8018 - acc: 0.7099 - val_loss: 0.7911 - val_acc: 0.7275\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 175s 32us/step - loss: 0.7890 - acc: 0.7300 - val_loss: 0.7882 - val_acc: 0.7312\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 175s 32us/step - loss: 0.7864 - acc: 0.7331 - val_loss: 0.7870 - val_acc: 0.7325\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 176s 32us/step - loss: 0.7849 - acc: 0.7351 - val_loss: 0.7863 - val_acc: 0.7329\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 178s 32us/step - loss: 0.7842 - acc: 0.7363 - val_loss: 0.7841 - val_acc: 0.7365\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 179s 33us/step - loss: 0.7836 - acc: 0.7368 - val_loss: 0.7837 - val_acc: 0.7369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a227e2a58>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kld.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".58\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LyKLDAdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500000 samples, validate on 5500000 samples\n",
      "Epoch 1/6\n",
      "5500000/5500000 [==============================] - 182s 33us/step - loss: 0.8037 - acc: 0.7069 - val_loss: 0.7915 - val_acc: 0.7266\n",
      "Epoch 2/6\n",
      "5500000/5500000 [==============================] - 170s 31us/step - loss: 0.7894 - acc: 0.7294 - val_loss: 0.7875 - val_acc: 0.7320\n",
      "Epoch 3/6\n",
      "5500000/5500000 [==============================] - 168s 31us/step - loss: 0.7863 - acc: 0.7336 - val_loss: 0.7855 - val_acc: 0.7348\n",
      "Epoch 4/6\n",
      "5500000/5500000 [==============================] - 168s 31us/step - loss: 0.7847 - acc: 0.7356 - val_loss: 0.7840 - val_acc: 0.7370\n",
      "Epoch 5/6\n",
      "5500000/5500000 [==============================] - 159s 29us/step - loss: 0.7839 - acc: 0.7368 - val_loss: 0.7838 - val_acc: 0.7372\n",
      "Epoch 6/6\n",
      "5500000/5500000 [==============================] - 165s 30us/step - loss: 0.7836 - acc: 0.7372 - val_loss: 0.7836 - val_acc: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1fdcef60>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson.fit(X_train, y_train, batch_size=64, epochs=6, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_result.append(\".78\")\n",
    "accuracy_result.append(\".73\")\n",
    "label_result.append(\"3LySigPoisRMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(activation_fn, loss_fn, optimizer_fn):\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(28, activation=activation_fn, input_shape=(28,)))\n",
    "    seq.add(Dense(10, activation=activation_fn))\n",
    "    seq.add(Dense(1, activation=activation_fn))\n",
    "    seq.compile(loss=loss_fn, optimizer=optimizer_fn, metrics=['accuracy'])\n",
    "    seq.summary()\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAIMCAYAAAB7di0zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd4VGXexvH7SYWQhAAJIYCA0lsI\nHaRXQVRc7Lq64ou4rkhZwLKia11xRV27RlewIC5FAcGCSBFFRUqoioD0GgIhAdJz3j/OyWQCCXkC\nuLD6/VwXFzOnPvPLKfc858yMcRxHAAAAQGkCznUDAAAA8L+B4AgAAAArBEcAAABYITgCAADACsER\nAAAAVgiOAAAAsEJwBAAAgBWCIwAAAKwQHAEAAGCF4AgAAAArQedqxdHR0U6dOnXO1eoBAADgWbFi\nxUHHcWJKm+6cBcc6depo+fLl52r1AAAA8BhjtttMx6VqAAAAWCE4AgAAwArBEQAAAFYIjgAAALBC\ncAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAV\ngiMAAACsEBwBAABgheAIAAAAKwRHAAAAWLEOjsaYJcaYJO/fHmPMzBPGtzXG5Bljrj77zQQAAMC5\nFmQ7oeM4XQoeG2NmSJrl9zxQ0lOSPj+rrQMAAMB5o8yXqo0xEZJ6SvLvcbxb0gxJB85SuwAAAHCe\nOZ17HP8g6UvHcdIkyRhTwxv22tlsGAAAAM4v1peq/dwg6U2/5/+SdK/jOHnGmFPOaIwZKmmoJNWq\nVes0Vn36Hnvwqf/q+s5XDz5277luAgAA+B9VpuBojKkiqZ3cHsYCbSR94IXGaEmXGmNyHceZeeL8\njuMkSkqUpDZt2jin22gAAAD895W1x/EaSXMcx8ksGOA4zoUFj40xk7zxJ4VGAAAA/G8r9R5HY8wn\nxpjq3tPrJU35dZsEAACA81GpPY6O41zq97h7KdPeeuZNAgAAwPmIX44BAACAFYIjAAAArBAcAQAA\nYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAA\nACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAA\nAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIA\nAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREA\nAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4A\nAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAE\nAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIj\nAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAc\nAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXg\nCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsE\nRwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFgh\nOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAK\nwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABW\nCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACw\nQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACA\nFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAA\nrFgHR2PMEmNMkvdvjzFmpjd8oDFmjTd8uTGm86/XXAAAAJwrQbYTOo7TpeCxMWaGpFne0y8lzXYc\nxzHGxEuaKqnRWW0lAAAAzrkyX6o2xkRI6ilppiQ5jnPUcRzHG11BklPSvAAAAPjfdTr3OP5B0peO\n46QVDDDG/MEY85OkuZJuO1uNAwAAwPnD+lK1nxskvek/wHGcjyR9ZIzpKukxSb2Lm9EYM1TSUEmq\nVavWaawa59oTDzx1rptwXnjgiXvPaP7HHqSOkvTgY2dWR5wd33Zke5Skjt+yPQKlKVOPozGmiqR2\ncnsWT+I4zleS6hpjoksYn+g4ThvHcdrExMSUubEAAAA4d8p6qfoaSXMcx8ksGGCMqWeMMd7jVpJC\nJKWcvSYCAADgfFBqcDTGfGKMqe49vV7SlBMmuUrSOmNMkqSXJV3n92EZAAAA/EaUeo+j4ziX+j3u\nXsz4pyRxgwwAAMBvHL8cAwAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAA\nrBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAA\nYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAA\nACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAA\nAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIA\nAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREA\nAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4A\nAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAE\nAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIj\nAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAc\nAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXg\nCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsE\nRwAAAFghOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFgh\nOAIAAMAKwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAK\nwREAAABWCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABW\nCI4AAACwQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMAKwREAAABWCI4AAACw\nQnAEAACAFYIjAAAArBAcAQAAYIXgCAAAACsERwAAAFghOAIAAMCKdXA0xiwxxiR5//YYY2Z6wxsZ\nY741xmQZY8b8ek0FAADAuRRkO6HjOF0KHhtjZkia5T09JGm4pCvPbtMAAABwPinzpWpjTISknpJm\nSpLjOAccx/lBUs5ZbhsAAADOI9Y9jn7+IOlLx3HSyjqjMWaopKGSVKtWrdNYNQAUemb0U+e6CeeF\n0c/ce66bAJw17Neu83W/Pp0Px9wgacrprMxxnETHcdo4jtMmJibmdBYBAACAc6RMwdEYU0VSO0lz\nf53mAAAA4HxV1h7HayTNcRwn89doDAAAAM5fpQZHY8wnxpjq3tPrdcJlamNMNWPMLkl/lTTOGLPL\nGBN59psKAACAc6nUD8c4jnOp3+PuxYzfJ6nm2W0WAAAAzjf8cgwAAACsEBwBAABgheAIAAAAKwRH\nAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4\nAgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArB\nEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYI\njgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBC\ncAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAV\ngiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACs\nEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABg\nheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAA\nKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAA\nWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAA\nwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAA\nAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAA\nALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQA\nAIAVgiMAAACsEBwBAABgheAIAAAAKwRHAAAAWAk61w34b8nIPK4Jzz8px3HkOI5q1qil/7vlDj3x\n9MMacMnlSohvXeoyZs6Zrl27d2rYHaOUm5+rF195VsYYDb9ztB558gEN+/NfFVMlpsj0K5OWKygo\nSPn5+QoNLafe3S9R29btfdPk5GbrsfEPqWaNWho6+C/Frnfpd0u0ZOki3fvXB8+oBjm5OWrXrp2y\nsrKUm5urq6++Wo888oi6d++uCRMmqE2bNqUu4+jRdH30yQwdSUtVXl6+KkVV0i3XDVZaeprmzput\nG6764ynnn/DyeIWGhMqYADlOvnp366vGDZpKkl5/+xXd8afia1AgLy9P87+apw0/rVNgYJCCg4PV\nq2sfNajb0L4Qp/DSm/9STHSsrrvyhmLHH049pHenvq3RD45Q165dz7iWM+e4tczPz1dUxUq6+Qa3\nlp98PlvXX33qWj774niFhIQqICBA+fn56tW9rxo3dGv5xqRXdPutpdfyy8XztOHHdQoKcmvZo2sf\nNah3ZrVcsPgLrUj6QRXCKigvL0/dOvdUfLMESdKHs6dq/Ya1umfUOIWGhkqSRowYoRdeeEE7d+7U\noEGDtGPHDqWmpqpixYqKi4tTQECAEhMTNWbMGO3du1flypVTeHi43nrrrZPWnX4sXVPnzVBqeqry\n8vNVObKShgwarCNH0zRz4Wz96fJT1/SJN8crNLiwpv069VWzem5NX5zyiu6+ofSafrZ0ntZucrfP\nkKBg9b24jxpfeGY1PXAoWdPnf6jMrEzl5uXqwhoX6po+gyRJO/buVPfu3bV7925FREQoLi5O48eP\nV/PmzfXwww/rjTfeUExMjI4dO6bmzZvr8ccf10UXXVRk++1wJE5DLuiju9a/rmG1B6hxeM1S23Qo\nO13/+GWGDmSnKtfJV1xoJT3TaLCSs9P03LbZ+keDU9d60MrxCgsMVYAxqhQcoYfqXqsqIRElTj/6\np4l6uN71iggqX+z4u9a/rpScdIUEBCnIBOm+iwapQYXqvnXFhkbp1aZ/9k3/pzXPK9fJ1+QWo5SZ\nl60nfpmupWGPKD8/XwEBARoxYoSefPJJ63164sSJev755yVJGzZsUMOGDRUYGKh+/fpp/Pjxp5z3\nRLm5uYqOjlZqaupJ48aNG6eJEycqJiZGWVlZ6tmzp1588UUFBATogQceUO/evdWjR49TLn/u3Ll6\n6KGHlJGRofz8fA0cOFBPPfVUmdp4ory8PA0fPlyLFy+WMUbly5fXtGnTVLt2baWnp2v06NF6++23\nVa5cOdWvX1/p6emaPHmyoqKi1Lx5czVq1EiZmZmKjIxU3cp11LpJK9+y2a/t9usmTZqcUXts/W6C\nY2hIOY28a6wiwiOVnZ2tp557XMtXLjutZeXn5+uV159XvpOvEX8Zo4CAkjtuq8bEatgdoyRJ33y3\nRHM+m6nIyEg1rN9YkvT10q8UEhKqPXt3+Q5Yv5agwCAtWLBA4eHhysnJUefOndW/f/8yLWP+V1+o\nbp16urhdZ0nSvgN7JUmREZGlhsYCt900VBXCKig5JVmTpvzbFxxLC43u+ucp/Wi67r59lIKCgnT0\naLq27th60nSnU8sDBw/IcRxt27FV2dnZCgkJKXHa0NDQM67lgsVfqO5F9dSxoJb7C2tZWmgsMPhm\nt5YHU5L19uR/+4JjaaFRkr5cPE9H09M17I7CWm47S7Xs2K6zOnfsqpRDB/Xamy+qaePmCgwMlCRV\nrlxFP/28QS2at1R+fr4WLlyoGjVqKDQ0VE8++aTGjRunL774Qr169dIjjzyiRx55xLfcyZMnq02b\nNkpMTNTYsWPVrX6nIuv9fOkXalC7nrq0cmu6J9mtacXwyFJPLgXuvHaoKpSvoAOHkpU449++E0xp\nJxdJ+mzpPKUdS9eYW9yaph9L15ZdZ17TmQtnq2urzr627E3eJ8k9ob47d7LmfDpXF198sSTp66+/\n1pYtW9S8eXNJ0qhRozRmzBhJ0n/+8x/17NlTa9asKbL9JlSqqw5RZTsJvrHrC7WtWE/Xxbm13nzM\nrXVMSGSpobHAS02GKiq4gl7b8Zne3rNQf61zRYnTPtNocKnL+3u969U4vKbmHFiul3d8oucbD/GN\nO56Xpf1ZqYoNjdK2jANF5pu67xtFB0fowIEDCg8P17p16zR48GANHDjQ6nVI0uDBgzV4sNvGOnXq\naOHChYqOjraevyzGjh2rkSNHKi8vT506ddI333yjLl266Iknnih13tWrV2vkyJGaO3euGjRooNzc\nXL3xxhsnTZebm6ugIPuI8P777yslJUVr1qxRQECAduzYocjISElubdLS0jRo0CClp6frrbfeUocO\nHXzzNmzYUKtWrZIkbd68WV06uNtUQXhkv7bbr9euXauYmJhi1nR2/W6CY0BAgCLC3Y04JzdbjuPI\nBJhip33in3/XFQMGqXnTFpKkx//5d1152VW+8a+++YKysjI1cthYBQXYl7BThy76ceN6LVg0zxcc\nk1avUOuENlq1eoVWJP2gtq3c3shFS77U4iULFBQUpKioSr5lrExark/mzfZtoNcNukn16zXUzDnT\n9fOmjXKUr4zjGWrcsKly83K1ZesmBZgA3Xn7CFWpXEXh4eFuDXJylJOTI2OKr0GXLl304osvKiHB\n7Snq1KmTXn31VR09lq76F9X3TVetapykwp644UNHKTsnWx9+PE3JKcmKia6q1COHdfklA1Ujrmgv\nRlZWpsqXK+w9ePTph/TQ2Ef1y/YtWrBkviqUr6D9yftVPa6GrrniOuXk5mh50g8a/Zd7fAe08PAI\nNW8S75v/4nadtXnrJvXrNUB5ubn6bMFc5efnq0ZcTV3R7w8KCgrS5ws/1U8//6iAgADVu6i++vca\nIElasz5JCc1a6UDKAf24aYNaNHVf++69u/TR3OkKDg5R7Zp1JEnGGB08eFD9+/dXenq6fv75Z61d\nu1aStGLFCo0ePVqxsbFKSkpSRkaG7rzzTs2cOVMZGRkKCQlRh9ZdlH40XXX9axlbWMvJ/3lbw+5w\na/nR7Gk66NXycOphXdZvoGpUL6aW5Qtr+fhTD2ncvY9q67YtWvjVfIWFVdCB5P2qXq2GrrrSreWK\nVT9o1LCitWzm1fLxpx5Sx/adtfmXTerXe4By83L1+XyvltVr6vL+bi3nLfhUG71a1r2ovvr1HlCk\nXVUqRys4OFgZmRkKr+Bue82bttDaDavVonlLLVq0SJ06ddKnn34qY4yOHDmi6OhoBQQEKCcnR5Uq\nVfL1TPp7/fXXdfjwYV9wfOmDVzWo15VKO5auBrULa1o9xq3poSOH9O+Zb2vsn9yafvD5NCUfSlbV\nylV1KO2wBvUcqAuqFa1pZnamwvy2z7+9+JD+cfej2rxzi+Z9626f+w7uV83YGrqxv1vT79f+oL/9\nX2FNIypEKKFhvG/+rq06a+P2Tbqim1vTjxe7Nb2gWk1d1cut6dwln2r9lh8VGBCgBrXr6/JuA5R+\nLF1RERV9bYmLqSZJ+ibpW7Vp0tp3cpGkzp07n1SvAtddd53mzp2rKVOmaMSIEZLcY0Guk6fijwTS\nnetf06g6V/h67+5Y96rGXnilUnLS1a5iYa3rVXBrvTfzkMZsfNvXk/f4lmnanpmsOuWqam/WYY2+\ncOBJPZoJkRdq2r6lkqR5B5P0zu6FciRdHNVId9V235ANWjlebzW/W6EBwRq3abKSs48oz3E0uEZP\n9Y5uUWR5zSJq6f29XxUZ1rNKvL5MWaMbq3fVFweT1LtKC3120A0rB3PSVS0kynd8vOiii5SXl1fm\n42N8fHyx03/33XcaNWqUMjMzFRYWpkmTJql+/fp688039dlnnyk9PV2//PKLrr76aj355JO++e67\n7z59+umnCgsL06xZs1S1atUiy83OzlZWVpaioqIkSX/84x919dVX68orr1TNmjU1ZMgQzZo1S3l5\neZo+fboaNGigp556Sg8++KAaNGggSQoKCtKdd97pmz82NlYrV65U27Ztdc899+i2227Ttm3bFB4e\nrsTERDVr1kwLFizQqFGjZIxRQECAlixZor179/quEEhSrVq1JEkbN27UihUrdOGFF+r222/Xs88+\nq6pVq/rGF1fXy7sN0KffzNO3a75nv/bY7Nfvv/++b7/+Nf2u7nHMzc3Vo+PH6alnH1ds1WpqndC2\n2OmaNonXkqWLJEmbtmyU4+T7TqgHkvfrcOphjfjLWAUHldwjVZLaF9TWkbQjkqTjx48rNS1VXTv3\nUIP6jbRs+beS3MvqC7+ar5uuv1X3j/m7MjIyfPPXvaie7v3rOD103+Pq1rmnZs6Z7ht3POOY7hwy\nQncNHaH1P61VSEiIHrrvcVWpXEWfz58rye1yT0hIUNWqVdWnTx+1b99exRkyZIgmTZokSfr555+V\nlZWl+Ph4tW/dUR/NnaF/v5eoRd8sUFp62knzLlvxncqVK6+7bx+pHp16as/e3UXGvzU5US8kPqd/\nv5eo3t36Frv+vfv36NI+l2v4HaN0OPWQtu/arkOHUxQVWVHlQssVO092TrZiY6rpz7fepRpxNTRj\nzjRdd+WNuvv2UcrPz9eyld/peMZx/bhxvYYPHaW7bx+p7p16+uZf++MaNWsSr/gmbrAp8OGc6RrQ\n54qTekSrVKmitLQ0bd68WX/84x/1+uuv+8atXr1azz//vNauXaujR49q9uzZWrZsma644grt2rVL\n1WLj1K5NR82aM0NvvZuoxV+XUMvl36l8ufK6a+hIdevcU3tPqOXEdxP10uvP6a13EtWre8m17N/3\ncg378ygdSj2kHTu369ChFFUsrZZVq+mO2+5S9eo19NHsabp20I0adodXyxVeLX9ar2F3jPK170R7\n9u5W5crRvtAouWHy+PFjysg4rilTpuj666/3jevVq5fmz5+v8PBwOY6jzMzMYttXr14930E8+XCy\ncvNyVT0mTp0SOmrqFzP06tREzf9+gY4cPbmmS1d/p7DQ8hp9y0j17tBTu/cXremrUxP19NvP6dWp\nierXqfia7jmwRwO7X66xt47SoSOHtG3Pdh1MTVFUxKlrWi26mkbceJdqxtbQB59N082X3agxf3Jr\nunSNW9N1m9dr7J9Gue1r79a0S6vOem3aG3rjw7f01Yolysh0jwn7UvarRtXqxa6vJK1atdJPP/1U\n5FjQtmJ9NY04+UQuSZdXbatPkldIknZkJCvHyVW9CnEaFNtRT/4yQ8M2JGrS7gVKzj651h/u/04R\nQeX1bvxI3VqzpzYe233SNJL0zeGfdFH5akrOTtOrOz7Vi01u19vxw/XjsZ1afGh9kWm/S92o6JBI\nvRM/UpNbjCq2p/T71J/VtVLRy3Y9KjfTokPrJElfH/5RnSs19o27LKaN3tuzWB06dFBsbKyio6NP\n6/hYksaNG+vrr7/WqlWr9OCDD2rcuHG+catXr9b06dO1Zs0avffee9qzZ48k6ciRI+rWrZtWr16t\njh07Frk14+mnn1ZCQoKqV6+u5s2b+3qhThQbG6tVq1ZpyJAhevbZZyVJ69atU+vWJd+atWXLFn35\n5Zf65z//qQcffFDt27fXmjVr9PDDD+vWW2/1rT8xMVFJSUn66quvVK5cOV1//fX68MMP1bJlS40Z\nM0ZJSUmSpPXr1ysnJ0dPP/10qb1xBXWtGVtDB1L2s1+XQcF+/d/wuwqOQUFBeui+xzVq2L1KSUnW\nhp/WFTtdn56X6EDyfmVnZ2vnbEtiAAAgAElEQVThV/PVoG4j37jy5corJydbSWtXnFYbHMfxPV78\n9QJVjIxShbBw9ejSSweS9ys3N1ebt2xSSEiI6l1UXwEBAUqIL7zXIy0tTc+99LQeefIBLVg8X8eP\nH/eNqxxVWZERkYqJiZUxRhe37yJJqhZbXalHDkuSAgMDlZSUpF27dmnZsmVat674GlxzzTWaM2eO\ncnJy9NZbb/kOGPUvaqC//uUetWnZTskpyXr53y/o2LGjRebdvmub4pu4PQCxVasptmq1IuNvu2mo\nhg8dpWG3j9ScebOUlZ110vprxl2gipEVFWACFFc1ztf+UwkwAWraqJkk6WBKsipFVVK0d89py+at\ntW3HVoWGhiooKEgffTJD639ap+DgYEnSrj07VSGsgipVrKS6deppz77dysg4rszMTGVmZejC2hdJ\nkhKat/StLz8/X/Hx8apVq5bef//9IrVs27at4uLiFBoaqiZNmmjXrl3KycnRL7/8otjYWLeWdRto\n5DC3lgcPJuvVN0+u5Y6d29SsqV8tY4vWcvDNQ33Bbe5nxdeyRnW/Wsba17KJV8uUE2qZEN9a2/1q\nOWvODG3wq6Ukfbvsaz3/ygQlTnxZPbr2Pmn5jRs209oNa/T999+rS5cuvuEVK1b0Be3Dhw/rqquu\n0r59+3zjb7rpJiUkJOj48ePKzs5WXl6elq1brjZN3BNhwzoN9Lfb7lH75u104FCynnvvBR09XrSm\nW3dvU0JDt6Zx0dV87/IL3HntUN8B/qMFxdf0gmoXKCrCrWn1mDgdsqxpfH23psmHk1W5YiXFVHJr\n2qZpa/2yy6tpYJCmzZuhtZsKa9quWRuNvXW0WjRori27ftELU15Rbm7uSeto3769GjdufMpeh4Jj\nkP+x4MdjO7Xl+L5ip+9Zubm+OfyTcvPzNCd5uS6NcWvdIaqBpre8R1dUbaftGcm6de0LOpxTtNar\n07epdxW31nXDqqluWNFaD9uQqD+teV7H8jJ1S43u+vHoTrWMvEiVgsMVZAJ1SXRLJaUVvSRYN6ya\nlh/ZrJe3f6qktK0KDyo8oT+y+QMNXPkPvbdnsa6udnGR+SKDwhQRVF5fHFytOuWrqlxA4fbaoEJ1\nTW95j+655x5dddVVCg4O1sKFC8t8fCxJamqqBg0apGbNmmnMmDFav74wDPfu3VsREREqX768GjVq\npB07dkiSypcv77v9pXXr1tq2bZtvnrFjxyopKUn79+9XSkqKpk+fruIMGjSo2PlP5ZprrvEFvK+/\n/lo333yzJKlv377as2ePjh07pk6dOmnkyJF68cUXlZaWpsDAQNWqVUsbN270XS7v0aOHFi1apOXL\nlys0NNQXVjdt2qSEhAR99913xa57zpw5ys3NU15+Pvu1pyz79X/D7yo4FqgUVUnVqlXXyqTlxY6v\nEBauKpWjtWDxF9qzd7d69+znGxcREanL+l2puZ/N1o8b1xc7/6ns2LVDFSu6lxXWbVit1COp+vsT\n9+uF156V4zj6dtnX3pTFXyKZPusD1apRS3+//wn96ab/U76T7xsX4N1DViDEu8RnAozy8/OLjIuK\nilL37t312WefFbuesLAw9enTR7NmzdLUqVN14403Fo4rH6YWTRN0zRXXqWb1mtq2s+iB3XYDrlKp\nisIrRCj54IGTxvnfW2MCApSfn6fKlaooNe2IsrJO3uEL5intHW1gQKD+fOswNW3YTD/+vF5vf+C+\ni1+zYbWSU5I14eXxevbVfyorK0vrN66TI0cl/S2ee+45xcbGat26dRo9erSys7N94/wvrwYHB6tD\nhw6aNWuWFi9erGrVCg9oYeXDFN8sQVddeZ1qxNUs5h5Du1pWrlxFFSpEKDm5mFoGFlPLylV0xLKW\nJf05AwMCdcdtw9SkcTP9uHG93n2/sEekY7vOGvGXMbp20I36cPZU5eTmFJm3edMWWrBonvr06XPS\n3ywwMFCXXXaZBg8erEsvvVTJycm+cZMnT1ZSUpI+/vhj9e/fX+u2bNDqn9eqVaME3zRh5cPUqnGC\nbux/nS6IralfTroXya6m0VFVFB4Wof0ppdTUBCjfyVN0VBWlph9RZjEnJMm+piNuHKbm9Ztp3eb1\neuPDwppWDI9Uu2ZtNXjgnxQQEKB9KftUrUqsdh/Y45vm+++/12OPPaYjR46U+LpWrVqlxo0Le9ui\noqLUMvIifZ/6c7HTlwsMUbuK9fTV4Q1akLJWfaMLax0ZFKa+0Qn6e73r1LhCzZNCnlNKrV9qMlRv\nx4/QQ/WuU0RQeau/TK3yMZrY/G7VDaum13Z+prd2zfeN+3u96zUj4V71iW6hZ7bOOmne3lXi9cy2\nWepzwqVtSQoLDNWgQYP0yiuv6Oabb1alSpVO6/hYnAceeECXXHKJ1q1bp5kzZxbpSfc/VgQGBvqC\ng/891v7D/YWEhKhfv3766quvThrnv2z/+Zs2baoVK0ru+KhQoYLv8YnH8oLn48aN0+uvv66jR4+q\nbdu22rRpkySpXLlyuvTSSzVhwgTde++9mjVrlg4ePKjt27erdu3auv7667Vz5041a9ZMOTlFjwlS\nYV2XrvlOMmK/9pzOfv1r+t0Ex2TvErPkXiLeu3e34uJK7gru2qm7vl32tcLDI1SlcpUi49q2bq+u\nnXvog+nvaceu7dZt+HbZ19q5a7t6duujI2mpSj+arr+N+bseeeBJPfLAk2rZoo1WJi1Xvbr1lZ2d\npV+2bpYkrV67yreMnJwcRVWqLEn6ctE863VL0rFjR32f0svIyND8+fPVqFGjEqcfMmSIhg8frrZt\n26pyZXedW7ZtVnaOG5CysrJ06HCKKkZGFZmv9gV1tO7HNZLcS/v7k4vvyTh67KgOpx5S1AnzlyQk\nOEStW7TRnC9mKzfPPQimH01T0rpVJ00bXSVGqUcOK+XQQUlS0rqVqlPrQmVlZykzK1MN6zXSpX0u\n1779e5Xv5Gvdj2t195ARGnPXfRpz13266epbtGb9apUvV17lQstp285tkqTV69zLL8nJydq/f7/i\n4uKUlZWlKVOmnDIwDxw4UMOHD1fDhg19J4Rftp5cy6iKRWtR64I6Wr/Br5YHSq5lauqhk+Y/VS1b\nJbTRJ5/71TI9rci25qtldNFarl67UnVqF9ayQb1G6t/3ct+He/w1adRMNeJqKGn1yiLDoypGqVf3\nS/SXvxRe/j948KB++OEHbdq0ybd9ZmVlqVy54i8RDRkyRLMWztYFsTUVVj5MkrRpR2FNM7OzlHIk\n5aTtq071Olr9s1vTfSn7tfdg8TVNP35Uh44cUqUybJ/tmrXRzIWFNU07mqYVG06uadXKMTqcdlgH\nD7s1XbFhperWdGuakZ2pxhc10sDul2uP9+Gzn7ZuVF5enrvMY+k6nnlckeEVdXFCR/2wfoWWLl3q\nW7b/VYgTzZgxQ/PmuYHd/1iw/Mhm1S5f8k31l1dtq39tm63GFWoqMsit9fIjm5WZ59b6WF6Wdmem\nKDa0aK1aRNTRghS31luP79eWjOJrXaBp+AValbZVqTnHlOfk64uDq9Uy8sIi0yRnpyk0IFj9Ylrq\nhriu2nhsT5HxQQGBuuOCS7T+6I6TPgTTtXIz3RTXVe0rNigyfE36Nu3ISFZqaqqys7O1bt067dix\no8zHx5IcOXJENWrUkCTfJe6zwXEcLV26VHXr1rWe55577tHjjz+uzZvd80teXp7vMvaJunbtqsmT\nJ0uS5s+fr5o1a6pChQrasmWL4uPjdf/996tly5a++xj37nW31/z8fK1du1a1a9dWYmKirrjiCt1y\nyy16//331bNnT7355psltq9fv35a+MMiVY+pzn5dxv36hhuK/zaQs+138+GY/cn79eHsqZLjvgu+\noGZt9erWV98tW6oPZ0/XRx+7Xf0R4REaM+JvatG8lWZ+PENtWrYrdnm9uvVVWlqaJr6bqGFDR0qS\nXnqtcOerFhunuGrVdSB5vx4dP873dTwD+l2hhvUba+ac6e49Zn4nxa6deuj5V56WUYB6dO2td6dM\nVFBQkGJiqurw4UOSpB5de2vuZ7O0fOUy34cpbKUfTVePHj2Ul5en/Px8XXvttbrssss0YcIEDRgw\nwNd93rFjR02bNk2tW7dWZGSk75OCkrRn327N+Xy2AgIC5DiOWie0Vc3qF+hw6iHfNO1bddSMj6fq\nxTf+pbhq1VWtapxC/e4PeWtyovtuLj9PfXv0U3h4yV/BcaLe3fpq/uJ5eiHxOQUFBikkJES9uvY5\nabrgoGANGnCNPvhosu/DMe1adVBG5nG9N+0d7923o/69L9O2HVsVGRGpSL+blOvUulAHZh1Q+tE0\nDbrsat+HY+pd6N6gvXfvXi1evFiTJk3Sgw8+qNatW/vuTbr//vuVkZGhmjVrqmPHjpLce5wiIyPV\nv39/X+/Ann27Nde/li3bqsYJtWzXuqM+nD1VLyf+S3Gx1RVbNa7INjPx3UQFBAQoLy9PfXqWrZa9\nuvfVl4vm6aXXnvO+jidEPbsVX8srL79G/5kx2ffhmLatOigj47je92rpOI769bms2PV079JL0z76\nQK1bFb2nuG3r9kVOePv379fQoUO1a9cu5eXlKSoqSjExMapTp44GDBig1NRUXXrpperWrZtv+wwN\nKae2TQvv19q1f7c+WjBbgQEByncctWvWVrWqXaBDRwprenFCR33w2VQ9886/VL1qdcVFxxW5f+nV\nqV5N8/M0oEs/RVSwr2m/Tn312Tfz9PQkt6YhwSHqd3HxNb3ukmv0zpzJvpvoO8Z30PHM45o46x3l\n5rk1vaK7W9Oft2/SrEUf+3pELutyqSK9dt084Ebdf//92r17t6pWraro6Gg99NBDvnU999xzeu+9\n93Ts2DHfBxtycnKKHAs6VqynTpUa6/09X2nMxkkKMm6fQrPw2nqiwU1qFF5TYYHlNKBqYa03Htut\nZ7fNVqBxa3151bZqEn6B9mYW1npQbEc9tmWqbl7zLzUIq656YXEKDyz+jYAkRYdE6s5a/TRsQ6L3\n4ZiG6lq5aZFpthzfp5d3fKIAGQWaQI298MqTlhMaEKzr47ro/T1f6W91r/YNrxAYqptrdD9p+t2Z\nKXpi9zTdGveyHMdReHi47r777jIfH0ty77336rbbbtM///nPUr8qx8bTTz+tSZMmKScnRy1bttQd\nd9xhPW/Lli01YcIEXXvttcrIyJAxpsRPjz/66KMaPHiw4uPjFR4erokTJ0qSJkyYoCVLliggIEDx\n8fHq27evvvjiC91+++3KznY/fNqxY0ffh24mTpyoMWPG6KabblJGRob69OmjunXrasCAATLGaP/+\n/apUqZJiY2MVGRmpCuUq6JKOhbe4sF/b7df/jU9US5L5b14X99emTRtn+fLiLxX/Gh57sGzfUbVn\n724lTnxZ4+57tEyfnD7fPfjYvdbT7tmzR927d9dPP/3k64p/4oHS65ifn6+8/DwFBwUr5XCKJr7/\nhkb+eUyRywD/6x54wr6O0sm1tN0e/Wt56FCKJk1+Q8P/8tupZVm2xxPt2bNHLZq20D2D/6oAY3/x\nxL+mB1NT9Pr0N3Tv4P/tmo5+5vTrKEnfdjz19picnaZhGxI1pUXZap3n5CvXyVNoQLB2ZaZo+IY3\n9J+EMQo+T4+pHb89s+Mjzhz7daEz3a/LyhizwnGcUr+E+H+3or+iWXNnaGXScnVo2+k3FRrL4p13\n3tEDDzygZ599tswHxZycHP17cqLy8/PkOHK/Bud/eOc9U2day4nvJfouZ1zW//ddywIFNe3fuW+Z\nTi6SlJ2bo9emFdZ0UC9qeiqfJq/Q6zvnaXjtAWWudWZ+ju7ekKhcJ0+OpLEX/uG8DY1lcSb7NErG\nfv2/gR7H35kz6eGR7Hocfw/K2uN4IrZH15luj8+Mpo7Sr9/j+HtRlh5H/HrYr13na48jb5UAAABg\nheAIAAAAKwRHAAAAWCE4AgAAwArBEQAAAFYIjgAAALBCcAQAAIAVgiMAAACsEBwBAABgheAIAAAA\nKwRHAAAAWLEOjsaYScaYrcaYJO9fgjf8JmPMGu/fUmNMi1+vuQAAADhXgso4/VjHcaafMGyrpG6O\n4xw2xvSXlCip/VlpHQAAAM4bZQ2OJ3EcZ6nf0+8k1TzTZQIAAOD8YxzHsZvQmEmSOkrKkvSlpPsc\nx8k6YZoxkho5jjOktOW1iYhwlrduXeYGn65tW3f819Z1PqtzYa0zmn87dZQk1T7DOrI9us50e9y5\nhTpK0gV1z6yOR1ZSR0mq2OrM6oizg/3adab7dVmZxYtXOI7TptTpyhAc4yTtkxQi93L0FsdxHvUb\n30PSK5I6O46TUsIyhkoa6j1tKGmj1cp/O6IlHTzXjfgNoI5nB3U8O6jj2UEdzw7qeHb8HutY23Gc\nmNImsg6ORWYyprukMY7jXOY9j5f0kaT+juP8XOYF/k4YY5bbpHmcGnU8O6jj2UEdzw7qeHZQx7OD\nOpasLJ+qjvP+N5KulLTOe15L0oeSbiY0AgAA/HaV+uEYY8wnkoZIes8YEyPJSEqS9GdvkockVZH0\nipsplUtKBwAA+O0pNTg6jnOp97BnCeOHyA2WKF3iuW7AbwR1PDuo49lBHc8O6nh2UMezgzqW4LTu\ncQQAAMDvDz85CAAAACu/m+BojClnjFlmjFltjFlvjHnEG77IGGN1T6Yx5lZjzEve4wBjzNvGmLeM\na5sxJrqY6ZONMauMMZuMMZ8bYy4+YZogY8xBY8yTp1hvd2PMnLK/6pOWczZqEGuMmeMtY4N3D6yM\nMdWNMSf+qlBx828zxqz1frZyrTFmoN+4paea15sm2Bgz3qvnOu/19Ldpuw3vdU05xfg63nqpZcnL\nfdgYs9tr1wZjzA1+4yYZY44bYyL8hj1vjHGMMTW8Nuw1xmQaY/Z7y1hhjGnj1XajV69vjDENi1n3\nb7WmDb3Xn2SM+dEYk+g3rp03bpMxZqUxZq4xprk3zv9vsckY86Expsl5tv2uNsbMM8ZUK2X6T4wx\nUacY7799/GC8n8X1W9eSE6ZPMsYUfMgzzBgzxds2M4wxx4wx//BbbunfbWfMYFP4k7zZftvR+NLm\nLWZZQcaY1BLGPe73N/3RGPOyMSbAG/eEcb8ar7TlD/D2qw3GmJ+MMU+VtY3FLDPQa8s677UvM8bU\n9sZFGGMSjTFZxpgjxpjl3nrbGGPqeTVf5b2e740xN5+wbPZri/36TNtjzXGc38U/uR/qCfceB0v6\nXlIHSYsktbFcxq2SXvKWlSjpfUkB3rhtkqKLm97veQ+534XZ2G/YpZK+kbRF3q0Dxay3u6Q550kN\nXpc0wu95fBnb4KuT3O/y3F7G+cdLeltSqPc8VtK1xUwXeBr1aSxpraTdkiqUME0dud8oQC1LXu7D\ncr+uS5LqS0qTFOw9nyRpjaQ/es8DvOe75H5vWk9J30qq4NX0EklLJbXxr63c74Od/Tuq6eeSBvo9\nb+63/G2SLvYb11nSlSf+Lbzn18k9BsWcZ9vvPyS9UJb5i1me//YxWNIXJ6wrSdIF3vPG3vN13vP7\nJT3rV5OmkpaVtSbFvbbTfC1BklJLGPe4pJEF25HcX2zrUoZlt5C0SVIDv3XdWVwbytjmmyV9oMJz\nYi1JUd7j6ZLmyT1nzpFUVe45r42kepKS/JZTT+5x+OZfaVv7Te/Xp7vNleXf76bH0XEd9Z4Ge/+K\nvcHTGLPkhHer3xj3uyoLPC/3k+S3OI6TX4Y2LJQbOIf6Db7BW94OuQepgnX2896RfS1pkN/wdsaY\npd67s6XG63Uxbu/mTGPMx8aYrcaYYcaYv3rTfWeMqXyWahAn9yRf8JrWeOPrnPDufaoxZo0x5j/e\nO8ji3rFHSjrst46j3v/dvXda070aTDauMEm3S7rb8X61yHGc/Y7jTC2Y3xjzqDHme0kdjTG9vNe/\n1rg9w6HedOO9d61rjDET/Npzo6R35R7grvBrV2vvne63ku7y1utIijZuL8YySc0lNfNmaW2MWezV\n4GdjzE5jzP3eu9S13jv933otC17TJknHJVXyGzxF7oFOct8UfSMp13seJfdLdx2522eqpOxiXu9Q\nuSf3gtf7W98+T3xda72HwyS97fj99KvjOF87jjOzmNcjx3H+I3f7vvE8OxZ8JTcwyBhzg1eTdcav\nJ8x4V3WMMRWM2/uy2pvmumKW962kGicMm6rC7e4GudthgThJu/1qslVuoDrdc8SJ03cwxnzr/b2/\nMcbU94YP8bajz43bc/TkCfONLzj2GGOqFrPoEEmhcvcTGWPeM8Zc6T3eZdyeqVVe/Rt489wr6THH\n+/o8x3FyHcd51W/+Z4wxCyX9w6v3bG/+pcaYZt50Pb12JRm3N6yCV8O9BedEx3F2OI6TatxzVGu5\nIfdNb9wBSTuLq6ukcEmjJQ1nvy77fl3c+LPuv5FOz5d/cjfcJElHJT3lDVukE95NSvqTpH95jxtI\nWu49vlXSIbknuuAT5tmmUnocvWFXSvrUe1xe0h5JYXJPhC94w8vJ3anqy+3Zmiqvx1HuRh/kPe4t\naYbfujZLipDbm3BE0p+9cc+p6DvUM6nBJXIPUgslPSCpuje8jgrfvY+R9Lr3uJncUNDGr05r5fba\nHZd0md86j3r/d/faX1Nuj9S3ct9txUtadYq/ryPvXaBfDQveVb8jaaSkynJ/sajgg2FRfvP/LKm2\npL7y682S2yPWzXv8tN/rDJe02qtloqTlXi3v8GoUJ/egfljSd948j0va/1uupYr2OLaStMRvuZMk\nXS23l6SSpDckdfNeS7Tc7TtDUr6kld64RTq5x/EDSRt/L9un3B60I5I+lTTKb/iH8uuxKGadvr+F\n37CRkl7V+XEsKOgFeknSU5Kqy30THSM3uC1QYS/LNrnbyFWS3vBrX8UT2+69xn+ccHxuIGmp93yV\npCZ+7UyQdMD7W+6TdOx0alLS+UBSRXm9UZL6SfqP93iI3N6/CLnng51eDQpCa39vumfl/syv5B5D\ndnt/u8OS3vFbz3t+9dolrydR0nBJr/kdz5qWsL28J2mmCnsNX5X0gPe4r9/f/lNJ7f2Og4Fyexi3\ne7WdICnBGz/Ia8v/t3f+MVtWZRz/fCUwyMTGyLAwlEwq2AgmtkLNRpt/aFhkyUiT+qNk6w8YNlvE\nXD/GAJup6WqSaIpTmBRLULGJsBoVkQwz3lbMcBQ6HCggvMWPb39c5+G9eXiel8f3BSKe67O92/Pe\nz33Ofe7rnOs651zXdT/3WCrRM7r0+rDHsSbX0s97SL1+y3rdrMzx/GsbjyOA7YO2RxMDY1xt99SA\nJcDVkvoCXyEmuxp/IhYX43rYDFU+Xw2ssr0XeBz4rKQ+wAjgJdt/c4yIhytlBgJLyi7rDipel1LX\nbtvbicH4q3L8BULBei0D208DFxIT/gjgecXve1YZT0zs2P4zYaiqXGl7JOGl+7Gksxpc/w+2tzp2\nrxtq7T8GBwk5QoQjXnLXj9I/CFxOhE07gQWSPkcYESRdAmy3vYV4F/sYSe+SNJBQ5tWlnocq1+tT\n7m0L4cGo9sU629scO9QXgfcVWV5ITEynrSwL0yX9lQiB3tag/qXA9cClwOHcM9u7iInoM8TC8nGg\nmvu2SNIGIpR9ZruMT9sLifDqEmKC+13Nk1GleFk2Sbqzm3ao1Hkq2IJVpT/PBuYAlwDP2d5u+wCw\nqMilygvABElzJV1m+43Kd4skbSW8anfXldsB7JR0PbCJyni1vaHcy3xibB4APtnDOaIR5wBLi92+\nnSNtxa+L3d4HdBALMIB9tp8sn9dz5BibX/ruXGCQpM83ue7SJuW7Y4m7ImnjKTbP9krgvOJd/C3w\nI0nfAM4uY+llYlx/u5RdpXjL3Fig0/b6cvyi0ueHI2zVaxPzYs0L/kC5dup1i3p9MmirhWMN268T\nu52rmny/F3gGmAh8gcjLqNFRjj0m6SMNih+LjxJGC2KxMUHSPwjFHkTkQUKTEAnwPWKBOBK4htjh\n1Ph35fOhyv+HqPvNzt7IwPYO24/YvgFYx9GGvaUBbHsz8Cqx86+nei8HS/v/DpyvyoMVdXTaPthd\nG8pkNI5Q9GuBp8pXk4ERpS82ExPZpFJPs76YXto/ivAI9GvS/gOEh20iYRxeqbTndJQlwB22LyZC\ngz+X9Pa64o8SY/kZ16V7lEnoCWLSWE54H2pMsT3a9jXELr1dxie2/2X7ftsTiTE1ktiUjKmccynw\nHWKD2YyqDfpf24IrS3/eWNpxzL4pk/JYYgE5R9LsytdTgAtKG+9pUPyxcvyoB+Bs77G91PY0YrG0\nk57NEY34AfB0sdvX0txu18YSHJmiUT1ebcd/iDFSL/f6uqvlXyTk14w3K5/r+6O26fg+EVk5C1hX\nC73b7rS9wvZMwoM8kdDf9xfb+igwlPD89W1wPzW5TiPsbuo1PdPrE0nbLBwlDVZ5Ik9SfyLM29FN\nkQXAXYTnaEf1C0fewdeB5YpXLrbahiuIkPR9ks4mdkjn2x5mexiRPze5tOsCScNL0cmVagYSYQqI\n8HTLHA8ZlNyWAeXzO4HhRGipym8IY4riSa9RTdrzbsLIb2ml/cWo/Ay4S1K/UscQSV9qcHoHMEzS\nB8r/NwCryy5zoO0VhGt/tOKJxOuIhOtaX0wEJpfJ7A1J40s9U8p1BxMJ3tuIcPRkutenXxKy7AD2\nlzpOO1k2uM5SIoT/5brjLxOeiXsrhwcpnrK8qDI+z+RIY16lLcZnqeeq4t1C8fTxIMIO3APcpCN/\nrWFAszZKmkSEHFeeSragwu+BKxS5dX0IvVpdPUHSecBe2w8T3rsx1e9t7wdmAR+T9KG6+n8BzCMe\nSqjW+QnF073nlL4bSUSWejRHNKDHdrs7JAn4OLHZbZV5wKza2FM8DT2jyblr6LJ5E4Cttt+UNNz2\nRttziND0xYpc8Nqric8g+nqL7a8R0a+HiP58lu5fGvIkcCsRvk697qIVvW76iyDHk2O+OeY0Ygjw\nYDFGZwCLbT8haSaxAMFVA/8AAAJsSURBVNxfzltr+zrb6yXtAhY2qqyUHQw8JemycnijpJr3ZDHh\nKv9iWXQMIBKuJ9neJOkm4FmXZNvCMkKppxELzOWSXiMUohYymVfuYwahgCdbBmMJN/+BUscC2+sk\nDaucc2+5zkbCqGwkQuc1Vkk6SOw4b7X96lu4h1lEjs9fJHUSu+PZ9SfZ7pQ0lQjrv43Yof6EyDVZ\nVjxgIryGlxOJ8f+sVLEG+HAxhFOB+yXtpWvCGUJ4D6cSnrM/ErlJECG3/oqQ2dpyrIMIV1S9A6ej\nLBvxXeARSffV1fvTuvPOJXJFhxJpAK8D24n8pOVEuG+5pDVtNj4hJoU7S50At9h+BUDxcMhcSe8l\n8vReI2ReY3qZ5N5BeHo+RXjHV50CtqBeLtskfYvIZROwwvayutNGAfOLrd0P3Nygnn2SfkjkvX21\ncnw34Qkj1lyHGV7ubWi57m7g7t7MEXXMJWzIN8u99ZZbyhzSl5BrvS41xfbz5Z4Wl02DibmnEbOB\nhaX/9hD2DmBmmfcOEX26Evg04RTpR8hwLZEjSSl3O+FB7E94FTcTen0IeI+knYQncBeh97dV2pF6\n3YJeO9LUTjj55pgmlF3tc8CI+lBau9BTGZTJqG9RouFEzuAHS1ilLUlZHn9SpiePlPXR5BxxYsix\ndurTTh7HlpF0I5GTMqNdDUIvZTCA2N31JXZXN7ez8qYsjz8p05NHyvpoco44MeRY+/8gPY5JkiRJ\nkiRJS7TNwzFJkiRJkiRJ78iFY5IkSZIkSdISuXBMkiRJkiRJWiIXjkmSJEmSJElL5MIxSZIkSZIk\naYlcOCZJkiRJkiQt8V/Tnzp9QC/MegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fd662e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "accycolor = []\n",
    "#Generate Colors on red/green axis based on execution time\n",
    "for index in range(0,len(loss_result)):\n",
    "    \n",
    "    percent_red = float(loss_result[index])\n",
    "    percent_green = 1 - percent_red\n",
    "    red_10 = int(percent_red * 255)\n",
    "    green_10 = int(percent_green * 255)\n",
    "    red_16 = str(hex(red_10))[-2:].replace(\"x\", \"0\")\n",
    "    green_16 = str(hex(green_10))[-2:].replace(\"x\", \"0\")\n",
    "    accycolor.append(\"#\"+str(red_16)+str(green_16)+\"88\")\n",
    "\n",
    "fig, ax = plot.subplots(figsize=(11, 9))\n",
    "rects = ax.bar(label_result, accuracy_result, color=accycolor)\n",
    "random_chance = 0\n",
    "plot.axhline(y=random_chance, color='r', linestyle='-')\n",
    "\n",
    "# Indicate Times.\n",
    "labels = [\"%s\" % l for l in label_result]\n",
    "\n",
    "\n",
    "plot.plot()\n",
    "for rect, label in zip(rects, labels):\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, .1, label,ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
